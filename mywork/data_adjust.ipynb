{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import jieba\n",
    "#import jieba.analyse\n",
    "import nltk\n",
    "\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string to list 用\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut = pd.read_csv('200_500_str.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentences_500        ['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...\n",
       "label                                                               10\n",
       "sentences_200_str    ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...\n",
       "sentences_500_str    ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...\n",
       "sentences_100_str    ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cut.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_clean =[]\n",
    "after_clean = data_cut['sentences_200'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "#讀取string 轉回list\n",
    "word_list=[]\n",
    "for i in range(len(after_clean)):\n",
    "    word_list.append(literal_eval(after_clean[i]))\n",
    "    if(i%10000==0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_100=[]\n",
    "for i in range(len(word_list)):\n",
    "    try:\n",
    "        first_100.append(word_list[i][:100])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str100=[]\n",
    "for i in range(len(first_100)):\n",
    "    str100.append(' '.join(first_100[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(str100[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut=data_cut.drop(['sentences_200','sentences_100'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences_500</th>\n",
       "      <th>label</th>\n",
       "      <th>sentences_200_str</th>\n",
       "      <th>sentences_500_str</th>\n",
       "      <th>sentences_100_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...</td>\n",
       "      <td>10</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...</td>\n",
       "      <td>10</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...</td>\n",
       "      <td>10</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...</td>\n",
       "      <td>10</td>\n",
       "      <td>訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...</td>\n",
       "      <td>訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...</td>\n",
       "      <td>訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...</td>\n",
       "      <td>10</td>\n",
       "      <td>lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...</td>\n",
       "      <td>lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...</td>\n",
       "      <td>lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentences_500  label  \\\n",
       "0  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...     10   \n",
       "1  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...     10   \n",
       "2  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...     10   \n",
       "3  ['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...     10   \n",
       "4  ['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...     10   \n",
       "\n",
       "                                   sentences_200_str  \\\n",
       "0  ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...   \n",
       "1  ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...   \n",
       "2  ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...   \n",
       "3  訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...   \n",
       "4  lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...   \n",
       "\n",
       "                                   sentences_500_str  \\\n",
       "0  ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...   \n",
       "1  ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...   \n",
       "2  ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...   \n",
       "3  訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...   \n",
       "4  lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...   \n",
       "\n",
       "                                   sentences_100_str  \n",
       "0  ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...  \n",
       "1  ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...  \n",
       "2  ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...  \n",
       "3  訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...  \n",
       "4  lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cut.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut.to_csv('200_500_str.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "work= data_cut['sentences_1000_str'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(clean)):\n",
    "    for i in range(len(clean[j])):\n",
    "        try:\n",
    "            clean[0].remove(' ')\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut['no_space']=clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut['first_1000'] = data_cut['no_space'].apply(lambda x:x[0:1000] if len(x)>1000 else x)\n",
    "data_cut['first_1000_str'] = data_cut['first_1000'].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut=data_cut.drop('after_clean', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cut.to_csv('all_data_cut.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list 轉\n",
    "str_list =[]\n",
    "for i in range(len(word_list)):\n",
    "    str_list.append(' '.join(word_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer(min_df=.0025, max_df=.1, stop_words='english', ngram_range=ngramrange)\n",
    "tvec_weights = tvec.fit_transform(df.stemmed.dropna())\n",
    "weights = np.asarray(tvec_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': tvec.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(norm=None)\n",
    "tfidf = vectorizer.fit_transform(data_cut['sentences_1000_str'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365082</th>\n",
       "      <td>情報</td>\n",
       "      <td>4.096438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478761</th>\n",
       "      <td>產品</td>\n",
       "      <td>3.307118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277786</th>\n",
       "      <td>台灣</td>\n",
       "      <td>2.382214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243879</th>\n",
       "      <td>公司</td>\n",
       "      <td>2.363193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340188</th>\n",
       "      <td>工作</td>\n",
       "      <td>2.040671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203549</th>\n",
       "      <td>中國</td>\n",
       "      <td>1.948018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378093</th>\n",
       "      <td>投資</td>\n",
       "      <td>1.851459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190162</th>\n",
       "      <td>一個</td>\n",
       "      <td>1.839492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226469</th>\n",
       "      <td>使用</td>\n",
       "      <td>1.818621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523036</th>\n",
       "      <td>美國</td>\n",
       "      <td>1.660442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342588</th>\n",
       "      <td>市場</td>\n",
       "      <td>1.636414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553705</th>\n",
       "      <td>蘋果</td>\n",
       "      <td>1.600428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402020</th>\n",
       "      <td>日本</td>\n",
       "      <td>1.563402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387009</th>\n",
       "      <td>提供</td>\n",
       "      <td>1.556683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374953</th>\n",
       "      <td>手機</td>\n",
       "      <td>1.500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289698</th>\n",
       "      <td>問題</td>\n",
       "      <td>1.387686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558365</th>\n",
       "      <td>表示</td>\n",
       "      <td>1.336719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406127</th>\n",
       "      <td>時間</td>\n",
       "      <td>1.329663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>ai</td>\n",
       "      <td>1.318565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232953</th>\n",
       "      <td>健康</td>\n",
       "      <td>1.313868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       term    weight\n",
       "365082   情報  4.096438\n",
       "478761   產品  3.307118\n",
       "277786   台灣  2.382214\n",
       "243879   公司  2.363193\n",
       "340188   工作  2.040671\n",
       "203549   中國  1.948018\n",
       "378093   投資  1.851459\n",
       "190162   一個  1.839492\n",
       "226469   使用  1.818621\n",
       "523036   美國  1.660442\n",
       "342588   市場  1.636414\n",
       "553705   蘋果  1.600428\n",
       "402020   日本  1.563402\n",
       "387009   提供  1.556683\n",
       "374953   手機  1.500002\n",
       "289698   問題  1.387686\n",
       "558365   表示  1.336719\n",
       "406127   時間  1.329663\n",
       "3886     ai  1.318565\n",
       "232953   健康  1.313868"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.asarray(tfidf.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': vectorizer.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df.to_csv('TFIDF',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = tfidf.toarray()\n",
    "\n",
    "tfidf_array.savetxt(\"tfidf_array.csv\", a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "save= tfidf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 25.51829803  22.19773225  18.46149397 ...,   9.68349122  10.51016979\n",
      "  11.76293276]\n"
     ]
    }
   ],
   "source": [
    "print(save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 414008)\t25.5182980334\n",
      "  (0, 128109)\t22.1977322512\n",
      "  (0, 388143)\t18.4614939664\n",
      "  (0, 230196)\t9.66878988925\n",
      "  (0, 243630)\t13.0915216099\n",
      "  (0, 139027)\t2.44293113661\n",
      "  (0, 391317)\t4.7545069789\n",
      "  (0, 334813)\t9.28578535166\n",
      "  (0, 158534)\t4.18932268561\n",
      "  (0, 74684)\t5.29062186364\n",
      "  (0, 178916)\t7.16774637465\n",
      "  (0, 351730)\t13.0357045327\n",
      "  (0, 473685)\t8.04627660876\n",
      "  (0, 152532)\t12.9710018065\n",
      "  (0, 174339)\t14.8091626177\n",
      "  (0, 177416)\t26.1552309752\n",
      "  (0, 266812)\t25.6321708138\n",
      "  (0, 410870)\t9.09164264954\n",
      "  (0, 142024)\t6.73905224194\n",
      "  (0, 382892)\t5.06713384573\n",
      "  (0, 489557)\t5.09470451437\n",
      "  (0, 263418)\t3.12671286495\n",
      "  (0, 42493)\t5.38027107937\n",
      "  (0, 32940)\t3.39273259512\n",
      "  (0, 65768)\t3.39667874694\n",
      "  :\t:\n",
      "  (94472, 69447)\t10.258855366\n",
      "  (94472, 59996)\t17.8594388375\n",
      "  (94472, 185935)\t9.278026113\n",
      "  (94472, 93370)\t10.258855366\n",
      "  (94472, 379822)\t9.74802974225\n",
      "  (94472, 104896)\t8.99034404055\n",
      "  (94472, 85240)\t9.81702261374\n",
      "  (94472, 192094)\t9.278026113\n",
      "  (94472, 32415)\t21.3286409482\n",
      "  (94472, 206324)\t10.6643204741\n",
      "  (94472, 254737)\t10.3766384017\n",
      "  (94472, 440629)\t9.74802974225\n",
      "  (94472, 144613)\t10.3766384017\n",
      "  (94472, 126375)\t10.6643204741\n",
      "  (94472, 68356)\t10.5101697943\n",
      "  (94472, 104859)\t10.6643204741\n",
      "  (94472, 168346)\t10.5101697943\n",
      "  (94472, 931)\t10.5101697943\n",
      "  (94472, 350967)\t9.56570818545\n",
      "  (94472, 206395)\t9.56570818545\n",
      "  (94472, 391509)\t9.56570818545\n",
      "  (94472, 103389)\t9.68349122111\n",
      "  (94472, 56562)\t9.68349122111\n",
      "  (94472, 80303)\t10.5101697943\n",
      "  (94472, 9312)\t11.7629327628\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import curses\n",
    "\n",
    "tfidf.toa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vectorizer=CountVectorizer()#该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j] 表示j词在i类文本下的词频\n",
    "transformer=TfidfTransformer()#该类会统计每个词语的tf-idf权值\n",
    "vec=vectorizer.fit_transform(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 77)\t1\n",
      "  (0, 61)\t1\n",
      "  (0, 146)\t1\n",
      "  (0, 290)\t1\n",
      "  (0, 179)\t1\n",
      "  (0, 272)\t1\n",
      "  (0, 104)\t1\n",
      "  (0, 164)\t1\n",
      "  (0, 294)\t1\n",
      "  (0, 140)\t1\n",
      "  (0, 85)\t1\n",
      "  (0, 239)\t1\n",
      "  (0, 157)\t1\n",
      "  (0, 41)\t1\n",
      "  (0, 143)\t1\n",
      "  (0, 236)\t1\n",
      "  (0, 155)\t1\n",
      "  (0, 188)\t1\n",
      "  (0, 178)\t1\n",
      "  (0, 278)\t1\n",
      "  (0, 162)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 135)\t1\n",
      "  :\t:\n",
      "  (0, 154)\t1\n",
      "  (0, 4)\t4\n",
      "  (0, 69)\t1\n",
      "  (0, 264)\t1\n",
      "  (0, 240)\t1\n",
      "  (0, 299)\t3\n",
      "  (0, 43)\t1\n",
      "  (0, 252)\t2\n",
      "  (0, 125)\t2\n",
      "  (0, 224)\t1\n",
      "  (0, 177)\t1\n",
      "  (0, 221)\t2\n",
      "  (0, 145)\t1\n",
      "  (0, 292)\t1\n",
      "  (0, 128)\t1\n",
      "  (0, 187)\t4\n",
      "  (0, 79)\t1\n",
      "  (0, 78)\t2\n",
      "  (0, 212)\t4\n",
      "  (0, 42)\t2\n",
      "  (0, 215)\t19\n",
      "  (0, 80)\t2\n",
      "  (0, 160)\t2\n",
      "  (0, 255)\t8\n",
      "  (0, 225)\t3\n"
     ]
    }
   ],
   "source": [
    "print(vec[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=transformer.fit_transform(vec)#第一个fit_transform是计算tf-idf，第二个fit_transform是将文本转为词频矩阵\n",
    "word=vectorizer.get_feature_names()#获取词袋模型中的所有词语\n",
    "weight=tfidf.toarray()#将tf-idf矩阵抽取出来，元素a[i][j]表示j词在i类文本中的tf-idf权重\n",
    "for i in range(len(weight)):#打印每类文本的tf-idf词语权重，第一个for遍历所有文本，第二个for便利某一类文本下的词语权重\n",
    "    print (\"-------这里输出第\",i,\"类文本的词语tf-idf权重------\")\n",
    "    for j in range(len(word)):\n",
    "        print (word[j],weight[i][j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
