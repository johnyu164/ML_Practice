{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jovyan/jt071-group23/jt071073/jt071073/data/for_CNN_data(73081).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_1000</th>\n",
       "      <th>sentences_1000_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"ETF關鍵報告\"台北開課公告(2018七月15日課程)綠角將在2018七月15日在台北開立...</td>\n",
       "      <td>10</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ETF關鍵報告\"台北開課公告(2018九月課程)此次同時公告九月預計在台北舉辦的兩個梯次\"...</td>\n",
       "      <td>10</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"ETF關鍵報告\"台北開課公告(2018八月12日課程)綠角將在2018八月12日在台北開立...</td>\n",
       "      <td>10</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#1訪客於2018/05/1114:24總覺得這股應該沒這麼慘5/11公佈季營收反而下殺.....</td>\n",
       "      <td>10</td>\n",
       "      <td>['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...</td>\n",
       "      <td>['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...</td>\n",
       "      <td>訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;lt;圖片擷取自:MONEYCONNEXION&amp;gt;雙親「理財」身教，凡遇錢事毫不馬虎！...</td>\n",
       "      <td>10</td>\n",
       "      <td>['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...</td>\n",
       "      <td>['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...</td>\n",
       "      <td>lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label  \\\n",
       "0  \"ETF關鍵報告\"台北開課公告(2018七月15日課程)綠角將在2018七月15日在台北開立...     10   \n",
       "1  \"ETF關鍵報告\"台北開課公告(2018九月課程)此次同時公告九月預計在台北舉辦的兩個梯次\"...     10   \n",
       "2  \"ETF關鍵報告\"台北開課公告(2018八月12日課程)綠角將在2018八月12日在台北開立...     10   \n",
       "3  #1訪客於2018/05/1114:24總覺得這股應該沒這麼慘5/11公佈季營收反而下殺.....     10   \n",
       "4  &lt;圖片擷取自:MONEYCONNEXION&gt;雙親「理財」身教，凡遇錢事毫不馬虎！...     10   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...   \n",
       "1  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...   \n",
       "2  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...   \n",
       "3  ['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...   \n",
       "4  ['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...   \n",
       "\n",
       "                                      sentences_1000  \\\n",
       "0  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...   \n",
       "1  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...   \n",
       "2  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...   \n",
       "3  ['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...   \n",
       "4  ['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...   \n",
       "\n",
       "                                  sentences_1000_str  \n",
       "0  ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...  \n",
       "1  ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...  \n",
       "2  ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...  \n",
       "3  訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...  \n",
       "4  lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv('data/data_uniqcontent_t.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>eigenWords</th>\n",
       "      <th>topKeyWords</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>class_no</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_1000</th>\n",
       "      <th>sentences_1000_str</th>\n",
       "      <th>t_sentences</th>\n",
       "      <th>title_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://jobs.inside.com.tw/jobs/24780-%E6%8D%B...</td>\n",
       "      <td>['工程', '熟悉', '經驗', '工作', '能力', '具備', 'php', '不...</td>\n",
       "      <td>['code', 'code review', 'com', 'container', 'c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSIDE Job Board</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['INSIDE', 'Job', 'Board']</td>\n",
       "      <td>INSIDE Job Board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.blocktempo.com/cryptoexchange-max-...</td>\n",
       "      <td>['交易', '基於', '交易所', '宣布', '以太', '貨幣', 'usdt', ...</td>\n",
       "      <td>['asset', 'asset exchange', 'coin', 'doubt', '...</td>\n",
       "      <td>\b4月23日晚間，7點46分，Maicoin旗下的虛擬貨幣交易所MaicoinAssetEx...</td>\n",
       "      <td>【MAX交易所宣布支援USDT】基於以太坊 ERC-20 的 USDT 跟原本的USDT差在...</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\x08', '月', '日', '晚間', '點', '分', 'Maicoin', ...</td>\n",
       "      <td>['\\x08', '月', '日', '晚間', '點', '分', 'Maicoin', ...</td>\n",
       "      <td>\b 月 日 晚間 點 分 Maicoin 旗下 虛擬 貨幣 交易所 MaicoinAsset...</td>\n",
       "      <td>['MAX', '交易所', '宣布', '支援', 'USDT', '以太', '坊', ...</td>\n",
       "      <td>MAX 交易所 宣布 支援 USDT 以太 坊 ERC USDT 原本 USDT 差 – B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://womany.net/read/article/15331?ref=rss&amp;u...</td>\n",
       "      <td>['工作', '轉職', '什麼', '自己', '公司', '辭職', '這份', '滿意...</td>\n",
       "      <td>['一下', '一個', '一定', '一年', '一樣', '一直', '下一', '不一...</td>\n",
       "      <td>\b你有轉職的考量嗎？你現今的工作可以符合你對未來人生的規劃嗎？透過五個轉職思考向度，檢視自己...</td>\n",
       "      <td>年前轉職：什麼情況下，你該毫不猶豫的換工作？｜女人迷 Womany</td>\n",
       "      <td>10</td>\n",
       "      <td>['\\x08', '轉職', '考量', '現今', '工作', '符合', '未來', '...</td>\n",
       "      <td>['\\x08', '轉職', '考量', '現今', '工作', '符合', '未來', '...</td>\n",
       "      <td>\b 轉職 考量 現今 工作 符合 未來 人生 規劃 透過 五個 轉職 思考 向度 檢視 是否...</td>\n",
       "      <td>['年前', '轉職', '情況', '下', '毫不猶豫', '的換', '工作', '女...</td>\n",
       "      <td>年前 轉職 情況 下 毫不猶豫 的換 工作 女人 迷 Womany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.blocktempo.com/facebook-we-cant-co...</td>\n",
       "      <td>['數據', '區塊', '所有', '資料', '透過', '中心化', '市場', '用...</td>\n",
       "      <td>['analytica', 'cambridge', 'cambridge analytic...</td>\n",
       "      <td>\b在網路時代，金錢可能不再是最吸引人事物，有一群人正覬覦著你的資料。透過數據收買你的心早在2...</td>\n",
       "      <td>【獨立觀點】當臉書用戶個資遭濫用，區塊鏈卻試圖幫你拿回「數據所有權」 – BlockTemp...</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...</td>\n",
       "      <td>['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...</td>\n",
       "      <td>\b 網路 時代 金錢 最 吸引 人 事物 一群 人正 覬覦 資料 透過 數據 收買 心早 美...</td>\n",
       "      <td>['獨立', '觀點', '當臉', '書', '用戶', '資遭', '濫用', '區塊'...</td>\n",
       "      <td>獨立 觀點 當臉 書 用戶 資遭 濫用 區塊 鏈 卻 試圖 幫 回 「 數據 所有權 – B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.blocktempo.com/facebook-we-cant-co...</td>\n",
       "      <td>['數據', '區塊', '所有', '資料', '臉書', '透過', '用戶', '中心...</td>\n",
       "      <td>['cambrigde', 'cambrigde analytica', 'datummar...</td>\n",
       "      <td>\b在網路時代，金錢可能不再是最吸引人事物，有一群人正覬覦著你的資料。透過數據收買你的心早在2...</td>\n",
       "      <td>【獨立觀點】當臉書用戶個資造濫用，區塊鏈卻試圖幫你拿回「數據所有權」 – BlockTemp...</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...</td>\n",
       "      <td>['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...</td>\n",
       "      <td>\b 網路 時代 金錢 最 吸引 人 事物 一群 人正 覬覦 資料 透過 數據 收買 心早 美...</td>\n",
       "      <td>['獨立', '觀點', '當臉', '書', '用戶', '資造', '濫用', '區塊'...</td>\n",
       "      <td>獨立 觀點 當臉 書 用戶 資造 濫用 區塊 鏈 卻 試圖 幫 回 「 數據 所有權 – B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://jobs.inside.com.tw/jobs/24780-%E6%8D%B...   \n",
       "1  https://www.blocktempo.com/cryptoexchange-max-...   \n",
       "2  http://womany.net/read/article/15331?ref=rss&u...   \n",
       "3  https://www.blocktempo.com/facebook-we-cant-co...   \n",
       "4  https://www.blocktempo.com/facebook-we-cant-co...   \n",
       "\n",
       "                                          eigenWords  \\\n",
       "0  ['工程', '熟悉', '經驗', '工作', '能力', '具備', 'php', '不...   \n",
       "1  ['交易', '基於', '交易所', '宣布', '以太', '貨幣', 'usdt', ...   \n",
       "2  ['工作', '轉職', '什麼', '自己', '公司', '辭職', '這份', '滿意...   \n",
       "3  ['數據', '區塊', '所有', '資料', '透過', '中心化', '市場', '用...   \n",
       "4  ['數據', '區塊', '所有', '資料', '臉書', '透過', '用戶', '中心...   \n",
       "\n",
       "                                         topKeyWords  \\\n",
       "0  ['code', 'code review', 'com', 'container', 'c...   \n",
       "1  ['asset', 'asset exchange', 'coin', 'doubt', '...   \n",
       "2  ['一下', '一個', '一定', '一年', '一樣', '一直', '下一', '不一...   \n",
       "3  ['analytica', 'cambridge', 'cambridge analytic...   \n",
       "4  ['cambrigde', 'cambrigde analytica', 'datummar...   \n",
       "\n",
       "                                             content  \\\n",
       "0                                                NaN   \n",
       "1  \b4月23日晚間，7點46分，Maicoin旗下的虛擬貨幣交易所MaicoinAssetEx...   \n",
       "2  \b你有轉職的考量嗎？你現今的工作可以符合你對未來人生的規劃嗎？透過五個轉職思考向度，檢視自己...   \n",
       "3  \b在網路時代，金錢可能不再是最吸引人事物，有一群人正覬覦著你的資料。透過數據收買你的心早在2...   \n",
       "4  \b在網路時代，金錢可能不再是最吸引人事物，有一群人正覬覦著你的資料。透過數據收買你的心早在2...   \n",
       "\n",
       "                                               title  class_no  \\\n",
       "0                                   INSIDE Job Board        10   \n",
       "1  【MAX交易所宣布支援USDT】基於以太坊 ERC-20 的 USDT 跟原本的USDT差在...         8   \n",
       "2                  年前轉職：什麼情況下，你該毫不猶豫的換工作？｜女人迷 Womany        10   \n",
       "3  【獨立觀點】當臉書用戶個資遭濫用，區塊鏈卻試圖幫你拿回「數據所有權」 – BlockTemp...         8   \n",
       "4  【獨立觀點】當臉書用戶個資造濫用，區塊鏈卻試圖幫你拿回「數據所有權」 – BlockTemp...         8   \n",
       "\n",
       "                                           sentences  \\\n",
       "0                                                 []   \n",
       "1  ['\\x08', '月', '日', '晚間', '點', '分', 'Maicoin', ...   \n",
       "2  ['\\x08', '轉職', '考量', '現今', '工作', '符合', '未來', '...   \n",
       "3  ['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...   \n",
       "4  ['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...   \n",
       "\n",
       "                                      sentences_1000  \\\n",
       "0                                                 []   \n",
       "1  ['\\x08', '月', '日', '晚間', '點', '分', 'Maicoin', ...   \n",
       "2  ['\\x08', '轉職', '考量', '現今', '工作', '符合', '未來', '...   \n",
       "3  ['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...   \n",
       "4  ['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...   \n",
       "\n",
       "                                  sentences_1000_str  \\\n",
       "0                                                NaN   \n",
       "1  \b 月 日 晚間 點 分 Maicoin 旗下 虛擬 貨幣 交易所 MaicoinAsset...   \n",
       "2  \b 轉職 考量 現今 工作 符合 未來 人生 規劃 透過 五個 轉職 思考 向度 檢視 是否...   \n",
       "3  \b 網路 時代 金錢 最 吸引 人 事物 一群 人正 覬覦 資料 透過 數據 收買 心早 美...   \n",
       "4  \b 網路 時代 金錢 最 吸引 人 事物 一群 人正 覬覦 資料 透過 數據 收買 心早 美...   \n",
       "\n",
       "                                         t_sentences  \\\n",
       "0                         ['INSIDE', 'Job', 'Board']   \n",
       "1  ['MAX', '交易所', '宣布', '支援', 'USDT', '以太', '坊', ...   \n",
       "2  ['年前', '轉職', '情況', '下', '毫不猶豫', '的換', '工作', '女...   \n",
       "3  ['獨立', '觀點', '當臉', '書', '用戶', '資遭', '濫用', '區塊'...   \n",
       "4  ['獨立', '觀點', '當臉', '書', '用戶', '資造', '濫用', '區塊'...   \n",
       "\n",
       "                                           title_str  \n",
       "0                                   INSIDE Job Board  \n",
       "1  MAX 交易所 宣布 支援 USDT 以太 坊 ERC USDT 原本 USDT 差 – B...  \n",
       "2                  年前 轉職 情況 下 毫不猶豫 的換 工作 女人 迷 Womany  \n",
       "3  獨立 觀點 當臉 書 用戶 資遭 濫用 區塊 鏈 卻 試圖 幫 回 「 數據 所有權 – B...  \n",
       "4  獨立 觀點 當臉 書 用戶 資造 濫用 區塊 鏈 卻 試圖 幫 回 「 數據 所有權 – B...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,df_t, on='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[pd.isnull(df['sentences_1000_str_x'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>sentences_x</th>\n",
       "      <th>sentences_1000_x</th>\n",
       "      <th>sentences_1000_str_x</th>\n",
       "      <th>url</th>\n",
       "      <th>eigenWords</th>\n",
       "      <th>topKeyWords</th>\n",
       "      <th>title</th>\n",
       "      <th>class_no</th>\n",
       "      <th>sentences_y</th>\n",
       "      <th>sentences_1000_y</th>\n",
       "      <th>sentences_1000_str_y</th>\n",
       "      <th>t_sentences</th>\n",
       "      <th>title_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"ETF關鍵報告\"台北開課公告(2018七月15日課程)綠角將在2018七月15日在台北開立...</td>\n",
       "      <td>10</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...</td>\n",
       "      <td>http://greenhornfinancefootnote.blogspot.tw/20...</td>\n",
       "      <td>['七月', '課程', '綠角', '台北', 'etf關鍵', '報告', '開課', ...</td>\n",
       "      <td>['allocation', 'analyst', 'art', 'assets', 'ba...</td>\n",
       "      <td>綠角財經筆記: \"ETF關鍵報告\"台北開課公告(2018七月15日課程)</td>\n",
       "      <td>0</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...</td>\n",
       "      <td>['綠角', '財經', '筆記', 'ETF', '關鍵', '報告', '台北', '開...</td>\n",
       "      <td>綠角 財經 筆記 ETF 關鍵 報告 台北 開課 公告 七月 日 課程</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"ETF關鍵報告\"台北開課公告(2018九月課程)此次同時公告九月預計在台北舉辦的兩個梯次\"...</td>\n",
       "      <td>10</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...</td>\n",
       "      <td>http://greenhornfinancefootnote.blogspot.com/2...</td>\n",
       "      <td>['六月', '綠角', '財經', '台北', '筆記', 'etf關鍵報', '報告',...</td>\n",
       "      <td>['allocation', 'art', 'asset', 'asset allocati...</td>\n",
       "      <td>綠角財經筆記: “ETF關鍵報告” 2018六月台北班學員課後回饋</td>\n",
       "      <td>0</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...</td>\n",
       "      <td>['綠角', '財經', '筆記', 'ETF', '關鍵', '報告', '六月', '台...</td>\n",
       "      <td>綠角 財經 筆記 ETF 關鍵 報告 六月 台北 班 學員 課後 回饋</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"ETF關鍵報告\"台北開課公告(2018八月12日課程)綠角將在2018八月12日在台北開立...</td>\n",
       "      <td>10</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...</td>\n",
       "      <td>http://greenhornfinancefootnote.blogspot.com/2...</td>\n",
       "      <td>['八月', '課程', '台北', '綠角', '關鍵', 'etf關鍵報', '報告',...</td>\n",
       "      <td>['allocation', 'analyst', 'art', 'asset', 'ato...</td>\n",
       "      <td>綠角財經筆記: \"ETF關鍵報告\"台北開課公告(2018八月12日課程)</td>\n",
       "      <td>0</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...</td>\n",
       "      <td>['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...</td>\n",
       "      <td>ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...</td>\n",
       "      <td>['綠角', '財經', '筆記', 'ETF', '關鍵', '報告', '台北', '開...</td>\n",
       "      <td>綠角 財經 筆記 ETF 關鍵 報告 台北 開課 公告 八月 日 課程</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#1訪客於2018/05/1114:24總覺得這股應該沒這麼慘5/11公佈季營收反而下殺.....</td>\n",
       "      <td>10</td>\n",
       "      <td>['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...</td>\n",
       "      <td>['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...</td>\n",
       "      <td>訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...</td>\n",
       "      <td>http://huodalife.pixnet.net/blog/post/46302915...</td>\n",
       "      <td>['實威', 'huodalife', '回覆', '訪客', '謝謝', '好的', 'h...</td>\n",
       "      <td>['heartpea', 'huodalife', 'lin', 'pd', '優股', '...</td>\n",
       "      <td>個股回顧_實威(8416) @ 豁達人生財經室 :: 痞客邦 ::</td>\n",
       "      <td>0</td>\n",
       "      <td>['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...</td>\n",
       "      <td>['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...</td>\n",
       "      <td>訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...</td>\n",
       "      <td>['個股', '回顧', '實威', '豁達', '人生', '財經', '室', '痞客'...</td>\n",
       "      <td>個股 回顧 實威 豁達 人生 財經 室 痞客 邦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;lt;圖片擷取自:MONEYCONNEXION&amp;gt;雙親「理財」身教，凡遇錢事毫不馬虎！...</td>\n",
       "      <td>10</td>\n",
       "      <td>['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...</td>\n",
       "      <td>['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...</td>\n",
       "      <td>lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...</td>\n",
       "      <td>https://www.cmoney.tw/notes/note-detail.aspx?n...</td>\n",
       "      <td>['投資', '雙親', '金錢', '富豪', '消費', '父母', '作者', '看著...</td>\n",
       "      <td>['cmoney官方', 'connexion', 'money', 'money conn...</td>\n",
       "      <td>窮人V.S.富人的關鍵差別！看懂這 3 種思想，人生由你決定...</td>\n",
       "      <td>0</td>\n",
       "      <td>['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...</td>\n",
       "      <td>['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...</td>\n",
       "      <td>lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...</td>\n",
       "      <td>['窮人', 'V', 'S', '富人', '關鍵', '差別', '懂', '種', '...</td>\n",
       "      <td>窮人 V S 富人 關鍵 差別 懂 種 思想 人生 決定</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label  \\\n",
       "0  \"ETF關鍵報告\"台北開課公告(2018七月15日課程)綠角將在2018七月15日在台北開立...     10   \n",
       "1  \"ETF關鍵報告\"台北開課公告(2018九月課程)此次同時公告九月預計在台北舉辦的兩個梯次\"...     10   \n",
       "2  \"ETF關鍵報告\"台北開課公告(2018八月12日課程)綠角將在2018八月12日在台北開立...     10   \n",
       "3  #1訪客於2018/05/1114:24總覺得這股應該沒這麼慘5/11公佈季營收反而下殺.....     10   \n",
       "4  &lt;圖片擷取自:MONEYCONNEXION&gt;雙親「理財」身教，凡遇錢事毫不馬虎！...     10   \n",
       "\n",
       "                                         sentences_x  \\\n",
       "0  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...   \n",
       "1  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...   \n",
       "2  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...   \n",
       "3  ['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...   \n",
       "4  ['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...   \n",
       "\n",
       "                                    sentences_1000_x  \\\n",
       "0  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...   \n",
       "1  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...   \n",
       "2  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...   \n",
       "3  ['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...   \n",
       "4  ['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...   \n",
       "\n",
       "                                sentences_1000_str_x  \\\n",
       "0  ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...   \n",
       "1  ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...   \n",
       "2  ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...   \n",
       "3  訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...   \n",
       "4  lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://greenhornfinancefootnote.blogspot.tw/20...   \n",
       "1  http://greenhornfinancefootnote.blogspot.com/2...   \n",
       "2  http://greenhornfinancefootnote.blogspot.com/2...   \n",
       "3  http://huodalife.pixnet.net/blog/post/46302915...   \n",
       "4  https://www.cmoney.tw/notes/note-detail.aspx?n...   \n",
       "\n",
       "                                          eigenWords  \\\n",
       "0  ['七月', '課程', '綠角', '台北', 'etf關鍵', '報告', '開課', ...   \n",
       "1  ['六月', '綠角', '財經', '台北', '筆記', 'etf關鍵報', '報告',...   \n",
       "2  ['八月', '課程', '台北', '綠角', '關鍵', 'etf關鍵報', '報告',...   \n",
       "3  ['實威', 'huodalife', '回覆', '訪客', '謝謝', '好的', 'h...   \n",
       "4  ['投資', '雙親', '金錢', '富豪', '消費', '父母', '作者', '看著...   \n",
       "\n",
       "                                         topKeyWords  \\\n",
       "0  ['allocation', 'analyst', 'art', 'assets', 'ba...   \n",
       "1  ['allocation', 'art', 'asset', 'asset allocati...   \n",
       "2  ['allocation', 'analyst', 'art', 'asset', 'ato...   \n",
       "3  ['heartpea', 'huodalife', 'lin', 'pd', '優股', '...   \n",
       "4  ['cmoney官方', 'connexion', 'money', 'money conn...   \n",
       "\n",
       "                                  title  class_no  \\\n",
       "0  綠角財經筆記: \"ETF關鍵報告\"台北開課公告(2018七月15日課程)         0   \n",
       "1     綠角財經筆記: “ETF關鍵報告” 2018六月台北班學員課後回饋         0   \n",
       "2  綠角財經筆記: \"ETF關鍵報告\"台北開課公告(2018八月12日課程)         0   \n",
       "3     個股回顧_實威(8416) @ 豁達人生財經室 :: 痞客邦 ::         0   \n",
       "4     窮人V.S.富人的關鍵差別！看懂這 3 種思想，人生由你決定...         0   \n",
       "\n",
       "                                         sentences_y  \\\n",
       "0  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...   \n",
       "1  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...   \n",
       "2  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...   \n",
       "3  ['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...   \n",
       "4  ['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...   \n",
       "\n",
       "                                    sentences_1000_y  \\\n",
       "0  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '七月', '日...   \n",
       "1  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '九月', '課...   \n",
       "2  ['ETF', '關鍵', '報告', '台北', '開課', '公告', '八月', '日...   \n",
       "3  ['訪客', '總覺', '這股', '應該', '慘', '公佈', '季營收', '下'...   \n",
       "4  ['lt', '圖片', '擷取', 'MONEYCONNEXION', 'gt', '雙親...   \n",
       "\n",
       "                                sentences_1000_str_y  \\\n",
       "0  ETF 關鍵 報告 台北 開課 公告 七月 日 課程 綠角將 七月 日 台北 開立 ETF ...   \n",
       "1  ETF 關鍵 報告 台北 開課 公告 九月 課程 此次 公告 九月 預計 台北 舉辦 兩個 ...   \n",
       "2  ETF 關鍵 報告 台北 開課 公告 八月 日 課程 綠角將 八月 日 台北 開立 ETF ...   \n",
       "3  訪客 總覺 這股 應該 慘 公佈 季營收 下 殺 明明 新聞 已經 說 月 營收 持平 市場...   \n",
       "4  lt 圖片 擷取 MONEYCONNEXION gt 雙親 「 理財 身教 凡遇 錢 事 馬...   \n",
       "\n",
       "                                         t_sentences  \\\n",
       "0  ['綠角', '財經', '筆記', 'ETF', '關鍵', '報告', '台北', '開...   \n",
       "1  ['綠角', '財經', '筆記', 'ETF', '關鍵', '報告', '六月', '台...   \n",
       "2  ['綠角', '財經', '筆記', 'ETF', '關鍵', '報告', '台北', '開...   \n",
       "3  ['個股', '回顧', '實威', '豁達', '人生', '財經', '室', '痞客'...   \n",
       "4  ['窮人', 'V', 'S', '富人', '關鍵', '差別', '懂', '種', '...   \n",
       "\n",
       "                             title_str  \n",
       "0  綠角 財經 筆記 ETF 關鍵 報告 台北 開課 公告 七月 日 課程  \n",
       "1  綠角 財經 筆記 ETF 關鍵 報告 六月 台北 班 學員 課後 回饋  \n",
       "2  綠角 財經 筆記 ETF 關鍵 報告 台北 開課 公告 八月 日 課程  \n",
       "3             個股 回顧 實威 豁達 人生 財經 室 痞客 邦  \n",
       "4         窮人 V S 富人 關鍵 差別 懂 種 思想 人生 決定  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['content'].str.len()<30].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "labels = to_categorical(np.asarray(df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val = train_test_split(df,labels,test_size=0.3,stratify=labels,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_title = Tokenizer()\n",
    "tokenizer_title.fit_on_texts(df['title_str'])\n",
    "train_title_sequences = tokenizer_title.texts_to_sequences(x_train['title_str'])\n",
    "val_title_sequences = tokenizer_title.texts_to_sequences(x_val['title_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_content = Tokenizer()\n",
    "tokenizer_content.fit_on_texts(df['sentences_1000_str_x'])\n",
    "train_content_sequences = tokenizer_content.texts_to_sequences(x_train['sentences_1000_str_x'])\n",
    "val_content_sequences = tokenizer_content.texts_to_sequences(x_val['sentences_1000_str_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_title_index = tokenizer_title.word_index\n",
    "word_content_index = tokenizer_content.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/jovyan/jt071-group23/jt071073/model/tokenizer_content.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer_content, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/jt071-group23/jt071073/model/tokenizer_title.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer_title, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655635\n",
      "85388\n"
     ]
    }
   ],
   "source": [
    "print(len(word_content_index))\n",
    "print(len(word_title_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (50600, 246)\n",
      "Shape of data tensor: (21687, 246)\n",
      "Shape of data tensor: (50600, 1000)\n",
      "Shape of data tensor: (21687, 1000)\n",
      "Shape of label tensor: (72287, 14)\n"
     ]
    }
   ],
   "source": [
    "MAX_CONTENT_LENGTH = 1000\n",
    "MAX_TITLE_LENGTH = 246\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "train_title_data = pad_sequences(train_title_sequences, maxlen=MAX_TITLE_LENGTH)\n",
    "val_title_data = pad_sequences(val_title_sequences, maxlen=MAX_TITLE_LENGTH)\n",
    "train_content_data = pad_sequences(train_content_sequences, maxlen=MAX_CONTENT_LENGTH)\n",
    "val_content_data = pad_sequences(val_content_sequences, maxlen=MAX_CONTENT_LENGTH)\n",
    "print('Shape of data tensor:', train_title_data.shape)\n",
    "print('Shape of data tensor:', val_title_data.shape)\n",
    "print('Shape of data tensor:', train_content_data.shape)\n",
    "print('Shape of data tensor:', val_content_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "wv_model = word2vec.KeyedVectors.load_word2vec_format('./renmin_zh_tw.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "word_vectors = wv_model.wv\n",
    "for word, vocab_obj in wv_model.wv.vocab.items():\n",
    "    embeddings_index[word] = word_vectors[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_content_index)+1, EMBEDDING_DIM))\n",
    "for word, i in word_content_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/jovyan/jt071-group23/jt071073/model/embedding_matrix.pickle', 'wb') as handle:\n",
    "    pickle.dump(embedding_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN1D content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 300)         196690800 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 998, 250)          225250    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 332, 250)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 83000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               24900300  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                4214      \n",
      "=================================================================\n",
      "Total params: 221,820,564\n",
      "Trainable params: 221,820,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_content_index) + 1, EMBEDDING_DIM, input_length=MAX_CONTENT_LENGTH))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(250, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(EMBEDDING_DIM, activation='relu'))\n",
    "model.add(Dense(labels.shape[1], activation='softmax'))\n",
    "model.summary()\n",
    "#plot_model(model, to_file='model.png',show_shapes=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196690800 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196690800 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50600 samples, validate on 21687 samples\n",
      "Epoch 1/5\n",
      "50600/50600 [==============================] - 63s 1ms/step - loss: 0.8440 - acc: 0.7645 - val_loss: 0.4229 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88122, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_C.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88122, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN1D_C.h5\n",
      "Epoch 2/5\n",
      "50600/50600 [==============================] - 52s 1ms/step - loss: 0.2381 - acc: 0.9314 - val_loss: 0.4780 - val_acc: 0.8722\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.88122\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.88122\n",
      "Epoch 3/5\n",
      "50600/50600 [==============================] - 52s 1ms/step - loss: 0.0826 - acc: 0.9770 - val_loss: 0.6033 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88122\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88122\n",
      "Epoch 4/5\n",
      "50600/50600 [==============================] - 52s 1ms/step - loss: 0.0295 - acc: 0.9935 - val_loss: 0.9374 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88122\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88122\n",
      "Epoch 5/5\n",
      "50600/50600 [==============================] - 52s 1ms/step - loss: 0.0205 - acc: 0.9966 - val_loss: 1.0250 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88122\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4fed0e208>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_C.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN1D_C.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/5\n",
      "50750/50750 [==============================] - 58s 1ms/step - loss: 0.8682 - acc: 0.7551 - val_loss: 0.4182 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87628, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_C.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87628, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN1D_C.h5\n",
      "Epoch 2/5\n",
      "50750/50750 [==============================] - 52s 1ms/step - loss: 0.2477 - acc: 0.9289 - val_loss: 0.4337 - val_acc: 0.8815\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87628 to 0.88148, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_C.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87628 to 0.88148, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN1D_C.h5\n",
      "Epoch 3/5\n",
      "50750/50750 [==============================] - 52s 1ms/step - loss: 0.0878 - acc: 0.9747 - val_loss: 0.5576 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88148\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88148\n",
      "Epoch 4/5\n",
      "50750/50750 [==============================] - 52s 1ms/step - loss: 0.0340 - acc: 0.9918 - val_loss: 0.7458 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88148\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.88148\n",
      "Epoch 5/5\n",
      "50750/50750 [==============================] - 52s 1ms/step - loss: 0.0211 - acc: 0.9957 - val_loss: 0.9864 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88148\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.88148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78c708e7f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_C.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN1D_C.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN1D content(Pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 1000, 300)         196700400 \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 998, 250)          225250    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 332, 250)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 83000)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 300)               24900300  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 14)                4214      \n",
      "=================================================================\n",
      "Total params: 221,830,164\n",
      "Trainable params: 25,129,764\n",
      "Non-trainable params: 196,700,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_content_index)+1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_CONTENT_LENGTH,\n",
    "                            trainable=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(250, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(EMBEDDING_DIM, activation='relu'))\n",
    "model.add(Dense(labels.shape[1], activation='softmax'))\n",
    "model.summary()\n",
    "#plot_model(model, to_file='model.png',show_shapes=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/5\n",
      "50750/50750 [==============================] - 21s 408us/step - loss: 0.9394 - acc: 0.7479 - val_loss: 0.5524 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83550, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_PC.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83550, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN1D_PC.h5\n",
      "Epoch 2/5\n",
      "50750/50750 [==============================] - 20s 385us/step - loss: 0.3467 - acc: 0.8939 - val_loss: 0.6086 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.83550\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.83550\n",
      "Epoch 3/5\n",
      "50750/50750 [==============================] - 20s 386us/step - loss: 0.1460 - acc: 0.9552 - val_loss: 0.6960 - val_acc: 0.8372\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83550 to 0.83720, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_PC.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83550 to 0.83720, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN1D_PC.h5\n",
      "Epoch 4/5\n",
      "50750/50750 [==============================] - 20s 388us/step - loss: 0.0620 - acc: 0.9812 - val_loss: 0.8083 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83720\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83720\n",
      "Epoch 5/5\n",
      "50750/50750 [==============================] - 20s 389us/step - loss: 0.0332 - acc: 0.9906 - val_loss: 0.9213 - val_acc: 0.8137\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.83720\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.83720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78e71a9940>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_PC.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN1D_PC.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN2D content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "embedding_layer = Embedding(len(word_content_index)+1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_CONTENT_LENGTH,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    196700400   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1000, 300, 1) 0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 998, 1, 512)  461312      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 997, 1, 512)  614912      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 996, 1, 512)  768512      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 1, 512)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1536)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1536)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 14)           21518       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 198,566,654\n",
      "Trainable params: 198,566,654\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "inputs = Input(shape=(MAX_CONTENT_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((MAX_CONTENT_LENGTH,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=labels.shape[1], activation='softmax')(dropout)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/20\n",
      "50750/50750 [==============================] - 248s 5ms/step - loss: 2.1047 - acc: 0.3931 - val_loss: 0.8439 - val_acc: 0.7669\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76691, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76691, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 2/20\n",
      "50750/50750 [==============================] - 239s 5ms/step - loss: 0.9584 - acc: 0.7029 - val_loss: 0.5988 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76691 to 0.81716, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76691 to 0.81716, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 3/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.6636 - acc: 0.7922 - val_loss: 0.5192 - val_acc: 0.8405\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81716 to 0.84047, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81716 to 0.84047, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 4/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.5240 - acc: 0.8365 - val_loss: 0.4785 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.84047 to 0.85044, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.84047 to 0.85044, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 5/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.4409 - acc: 0.8631 - val_loss: 0.4536 - val_acc: 0.8565\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.85044 to 0.85651, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.85044 to 0.85651, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 6/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.3778 - acc: 0.8841 - val_loss: 0.4352 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85651 to 0.86286, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.85651 to 0.86286, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 7/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.3280 - acc: 0.9009 - val_loss: 0.4162 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.86286 to 0.86879, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.86286 to 0.86879, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 8/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.2849 - acc: 0.9152 - val_loss: 0.4048 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.86879 to 0.87182, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.86879 to 0.87182, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 9/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.2496 - acc: 0.9267 - val_loss: 0.3979 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.87182 to 0.87426, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.87182 to 0.87426, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 10/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.2174 - acc: 0.9388 - val_loss: 0.3874 - val_acc: 0.8782\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.87426 to 0.87821, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.87426 to 0.87821, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 11/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.1873 - acc: 0.9490 - val_loss: 0.3830 - val_acc: 0.8794\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87821 to 0.87941, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.87821 to 0.87941, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 12/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.1597 - acc: 0.9595 - val_loss: 0.3777 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.87941 to 0.88134, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.87941 to 0.88134, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 13/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.1375 - acc: 0.9664 - val_loss: 0.3743 - val_acc: 0.8824\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.88134 to 0.88240, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.88134 to 0.88240, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 14/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.1162 - acc: 0.9735 - val_loss: 0.3721 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.88240 to 0.88304, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.88240 to 0.88304, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 15/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.0974 - acc: 0.9793 - val_loss: 0.3681 - val_acc: 0.8846\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.88304 to 0.88465, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.88304 to 0.88465, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 16/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.0822 - acc: 0.9837 - val_loss: 0.3688 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.88465 to 0.88548, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.88465 to 0.88548, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 17/20\n",
      "50750/50750 [==============================] - 240s 5ms/step - loss: 0.0686 - acc: 0.9883 - val_loss: 0.3672 - val_acc: 0.8869\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.88548 to 0.88695, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.88548 to 0.88695, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 18/20\n",
      "50750/50750 [==============================] - 239s 5ms/step - loss: 0.0585 - acc: 0.9906 - val_loss: 0.3674 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.88695 to 0.88741, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.88695 to 0.88741, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5\n",
      "Epoch 19/20\n",
      "50750/50750 [==============================] - 239s 5ms/step - loss: 0.0487 - acc: 0.9928 - val_loss: 0.3707 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.88741\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.88741\n",
      "Epoch 20/20\n",
      "50750/50750 [==============================] - 241s 5ms/step - loss: 0.0409 - acc: 0.9945 - val_loss: 0.3722 - val_acc: 0.8872\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.88741\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.88741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02256b2e48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN2D_C.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=20, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN2D content(Pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "embedding_layer = Embedding(len(word_content_index)+1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_CONTENT_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1000, 300)    196700400   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1000, 300, 1) 0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 998, 1, 512)  461312      reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 997, 1, 512)  614912      reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 996, 1, 512)  768512      reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 1, 512)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1536)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1536)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14)           21518       dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 198,566,654\n",
      "Trainable params: 1,866,254\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "inputs = Input(shape=(MAX_CONTENT_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((MAX_CONTENT_LENGTH,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=labels.shape[1], activation='softmax')(dropout)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/20\n",
      "50750/50750 [==============================] - 178s 4ms/step - loss: 2.1055 - acc: 0.3865 - val_loss: 0.8936 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76277, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76277, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 2/20\n",
      "50750/50750 [==============================] - 177s 3ms/step - loss: 1.0308 - acc: 0.6782 - val_loss: 0.6490 - val_acc: 0.8013\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76277 to 0.80134, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76277 to 0.80134, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 3/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.7497 - acc: 0.7648 - val_loss: 0.5626 - val_acc: 0.8243\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.80134 to 0.82433, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.80134 to 0.82433, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 4/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.6238 - acc: 0.8020 - val_loss: 0.5211 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.82433 to 0.83826, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.82433 to 0.83826, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 5/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.5427 - acc: 0.8299 - val_loss: 0.4912 - val_acc: 0.8461\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.83826 to 0.84608, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.83826 to 0.84608, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 6/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.4887 - acc: 0.8472 - val_loss: 0.4719 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.84608 to 0.85008, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.84608 to 0.85008, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 7/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.4495 - acc: 0.8579 - val_loss: 0.4615 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.85008 to 0.85270, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.85008 to 0.85270, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 8/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.4135 - acc: 0.8702 - val_loss: 0.4480 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.85270 to 0.85729, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.85270 to 0.85729, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 9/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.3855 - acc: 0.8791 - val_loss: 0.4383 - val_acc: 0.8610\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.85729 to 0.86102, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.85729 to 0.86102, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 10/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.3609 - acc: 0.8867 - val_loss: 0.4309 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.86102 to 0.86116, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.86102 to 0.86116, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 11/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.3362 - acc: 0.8953 - val_loss: 0.4243 - val_acc: 0.8640\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.86116 to 0.86401, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.86116 to 0.86401, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 12/20\n",
      "50750/50750 [==============================] - 176s 3ms/step - loss: 0.3150 - acc: 0.9032 - val_loss: 0.4170 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.86401 to 0.86722, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.86401 to 0.86722, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 13/20\n",
      "50750/50750 [==============================] - 177s 3ms/step - loss: 0.2921 - acc: 0.9095 - val_loss: 0.4122 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.86722 to 0.86833, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.86722 to 0.86833, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 14/20\n",
      "50750/50750 [==============================] - 177s 3ms/step - loss: 0.2734 - acc: 0.9155 - val_loss: 0.4071 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.86833 to 0.87086, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.86833 to 0.87086, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 15/20\n",
      "50750/50750 [==============================] - 177s 3ms/step - loss: 0.2565 - acc: 0.9222 - val_loss: 0.4031 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.87086 to 0.87205, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.87086 to 0.87205, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 16/20\n",
      "50750/50750 [==============================] - 177s 3ms/step - loss: 0.2418 - acc: 0.9277 - val_loss: 0.3990 - val_acc: 0.8734\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.87205 to 0.87343, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.87205 to 0.87343, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 17/20\n",
      "50750/50750 [==============================] - 177s 3ms/step - loss: 0.2250 - acc: 0.9337 - val_loss: 0.3985 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.87343 to 0.87380, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.87343 to 0.87380, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 18/20\n",
      "50750/50750 [==============================] - 177s 3ms/step - loss: 0.2082 - acc: 0.9392 - val_loss: 0.3957 - val_acc: 0.8765\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.87380 to 0.87647, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.87380 to 0.87647, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n",
      "Epoch 19/20\n",
      "50750/50750 [==============================] - 177s 3ms/step - loss: 0.1975 - acc: 0.9426 - val_loss: 0.3940 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.87647\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.87647\n",
      "Epoch 20/20\n",
      "50750/50750 [==============================] - 179s 4ms/step - loss: 0.1838 - acc: 0.9475 - val_loss: 0.3921 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.87647 to 0.87670, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.87647 to 0.87670, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0198435908>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN2D_PC.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=20, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttentionGRU content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    196700400   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1000, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 120)    130320      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 120)    65520       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000, 240)    0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last (Lambda)                   (None, 240)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 240)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 240)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_1 (A (None, 240)          240         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 960)          0           last[0][0]                       \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 attention_weighted_average_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 960)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 144)          138384      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14)           2030        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 197,036,894\n",
      "Trainable params: 197,036,894\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from modelzoo import get_av_rnn\n",
    "model = get_av_rnn(len(word_content_index)+1, EMBEDDING_DIM, embedding_matrix, MAX_CONTENT_LENGTH, 14, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/5\n",
      "50750/50750 [==============================] - 156s 3ms/step - loss: 0.8207 - acc: 0.7391 - val_loss: 0.3919 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87601, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_C.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87601, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_C.h5\n",
      "Epoch 2/5\n",
      "50750/50750 [==============================] - 146s 3ms/step - loss: 0.3152 - acc: 0.9025 - val_loss: 0.3456 - val_acc: 0.8963\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87601 to 0.89633, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_C.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87601 to 0.89633, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_C.h5\n",
      "Epoch 3/5\n",
      "50750/50750 [==============================] - 146s 3ms/step - loss: 0.1194 - acc: 0.9639 - val_loss: 0.4125 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89633\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89633\n",
      "Epoch 4/5\n",
      "50750/50750 [==============================] - 146s 3ms/step - loss: 0.0317 - acc: 0.9909 - val_loss: 0.5076 - val_acc: 0.8905\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89633\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89633\n",
      "Epoch 5/5\n",
      "50750/50750 [==============================] - 146s 3ms/step - loss: 0.0132 - acc: 0.9967 - val_loss: 0.5964 - val_acc: 0.8846\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89633\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92781eef28>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_C.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/AVRNN_C.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttentionGRU content(Pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1000, 300)    196700400   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1000, 300)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 120)    130320      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 120)    65520       bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000, 240)    0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last (Lambda)                   (None, 240)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 240)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 240)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_2 (A (None, 240)          240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 960)          0           last[0][0]                       \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "                                                                 attention_weighted_average_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 960)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 144)          138384      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 14)           2030        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 197,036,894\n",
      "Trainable params: 336,494\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from modelzoo import get_av_rnn\n",
    "model = get_av_rnn(len(word_content_index)+1, EMBEDDING_DIM, embedding_matrix, MAX_CONTENT_LENGTH, 14, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/5\n",
      "50750/50750 [==============================] - 105s 2ms/step - loss: 0.9862 - acc: 0.6824 - val_loss: 0.5432 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82346, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_PC.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82346, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_PC.h5\n",
      "Epoch 2/5\n",
      "50750/50750 [==============================] - 104s 2ms/step - loss: 0.5781 - acc: 0.8147 - val_loss: 0.4614 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.82346 to 0.85067, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_PC.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.82346 to 0.85067, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_PC.h5\n",
      "Epoch 3/5\n",
      "50750/50750 [==============================] - 104s 2ms/step - loss: 0.5148 - acc: 0.8362 - val_loss: 0.4341 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85067 to 0.86157, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_PC.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85067 to 0.86157, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_PC.h5\n",
      "Epoch 4/5\n",
      "50750/50750 [==============================] - 104s 2ms/step - loss: 0.4781 - acc: 0.8462 - val_loss: 0.4190 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86157 to 0.86608, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_PC.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.86157 to 0.86608, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_PC.h5\n",
      "Epoch 5/5\n",
      "50750/50750 [==============================] - 104s 2ms/step - loss: 0.4472 - acc: 0.8554 - val_loss: 0.4042 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86608 to 0.87012, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_PC.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86608 to 0.87012, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_PC.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92781eee80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.AVRNN_PC.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/AVRNN_PC.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiGRU content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    196700400   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1000, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1000, 128)    140544      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 128)    0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1000, 128)    74496       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384)          0           lambda_1[0][0]                   \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 384)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 72)           27720       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14)           1022        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 196,944,182\n",
      "Trainable params: 196,944,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from modelzoo import get_dropout_bi_gru\n",
    "model = get_dropout_bi_gru(len(word_content_index)+1, EMBEDDING_DIM, embedding_matrix, MAX_CONTENT_LENGTH, 14, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/5\n",
      "50750/50750 [==============================] - 147s 3ms/step - loss: 0.9398 - acc: 0.7054 - val_loss: 0.4299 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87348, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_C.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87348, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGRU_C.h5\n",
      "Epoch 2/5\n",
      "50750/50750 [==============================] - 137s 3ms/step - loss: 0.3292 - acc: 0.9009 - val_loss: 0.3695 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87348 to 0.89182, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_C.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.87348 to 0.89182, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGRU_C.h5\n",
      "Epoch 3/5\n",
      "50750/50750 [==============================] - 137s 3ms/step - loss: 0.1289 - acc: 0.9629 - val_loss: 0.4468 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89182\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89182\n",
      "Epoch 4/5\n",
      "50750/50750 [==============================] - 137s 3ms/step - loss: 0.0412 - acc: 0.9891 - val_loss: 0.5708 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89182\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89182\n",
      "Epoch 5/5\n",
      "50750/50750 [==============================] - 137s 3ms/step - loss: 0.0185 - acc: 0.9952 - val_loss: 0.6323 - val_acc: 0.8800\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89182\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f75646198>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_C.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/BiGRU_C.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiGRU content(Pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1000, 300)    196700400   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1000, 300)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 1000, 128)    140544      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1000, 128)    0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1000, 128)    74496       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 384)          0           lambda_2[0][0]                   \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 384)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 72)           27720       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 14)           1022        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 196,944,182\n",
      "Trainable params: 243,782\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from modelzoo import get_dropout_bi_gru\n",
    "model = get_dropout_bi_gru(len(word_content_index)+1, EMBEDDING_DIM, embedding_matrix, MAX_CONTENT_LENGTH, 14, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/5\n",
      "50750/50750 [==============================] - 99s 2ms/step - loss: 1.1334 - acc: 0.6364 - val_loss: 0.6411 - val_acc: 0.7917\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79173, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_PC.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79173, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGRU_PC.h5\n",
      "Epoch 2/5\n",
      "50750/50750 [==============================] - 96s 2ms/step - loss: 0.6051 - acc: 0.8117 - val_loss: 0.4935 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79173 to 0.84309, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_PC.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79173 to 0.84309, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGRU_PC.h5\n",
      "Epoch 3/5\n",
      "50750/50750 [==============================] - 97s 2ms/step - loss: 0.5155 - acc: 0.8395 - val_loss: 0.4504 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84309 to 0.85844, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_PC.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84309 to 0.85844, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGRU_PC.h5\n",
      "Epoch 4/5\n",
      "50750/50750 [==============================] - 97s 2ms/step - loss: 0.4727 - acc: 0.8533 - val_loss: 0.4212 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85844 to 0.86759, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_PC.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85844 to 0.86759, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGRU_PC.h5\n",
      "Epoch 5/5\n",
      "50750/50750 [==============================] - 97s 2ms/step - loss: 0.4390 - acc: 0.8630 - val_loss: 0.4048 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86759 to 0.87293, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_PC.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86759 to 0.87293, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGRU_PC.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19933d4320>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.BiGRU_PC.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/BiGRU_PC.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit(train_content_data, y_train,\n",
    "          validation_data=(val_content_data, y_val),\n",
    "          epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN1D content(Pretrain)+title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 246, 300)     25657200    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "content (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 246, 300)     0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1000, 300)    196700400   content[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 244, 250)     225250      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 998, 250)     225250      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 81, 250)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 332, 250)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20250)        0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 83000)        0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 300)          6075300     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 300)          24900300    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 600)          0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 14)           8414        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 253,792,114\n",
      "Trainable params: 57,091,714\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, GlobalMaxPooling1D, concatenate\n",
    "\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "dropout_t = Dropout(0.2)(embedded_sent_t)\n",
    "conv1d_t = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(dropout_t)\n",
    "flatten_t = Flatten()(MaxPooling1D(3)(conv1d_t))\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(flatten_t)\n",
    "\n",
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH, ), dtype='int32', name='content')\n",
    "embedded_sent_c = Embedding(len(word_content_index) + 1, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix], input_length=MAX_CONTENT_LENGTH,\n",
    "                           trainable=False)(content_inputs)\n",
    "conv1d_c = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(embedded_sent_c)\n",
    "flatten_c = Flatten()(MaxPooling1D(3)(conv1d_c))\n",
    "encode_content = Dense(EMBEDDING_DIM, activation='relu')(flatten_c)\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/5\n",
      "50750/50750 [==============================] - 29s 575us/step - loss: 0.6955 - acc: 0.8241 - val_loss: 0.3619 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89490, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_PC_CNN1D_T.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89490, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN1D_PC_CNN1D_T.h5\n",
      "Epoch 2/5\n",
      "50750/50750 [==============================] - 27s 541us/step - loss: 0.1633 - acc: 0.9527 - val_loss: 0.3565 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89490 to 0.90391, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_PC_CNN1D_T.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.89490 to 0.90391, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN1D_PC_CNN1D_T.h5\n",
      "Epoch 3/5\n",
      "50750/50750 [==============================] - 28s 542us/step - loss: 0.0373 - acc: 0.9899 - val_loss: 0.5127 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90391\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90391\n",
      "Epoch 4/5\n",
      "50750/50750 [==============================] - 28s 542us/step - loss: 0.0119 - acc: 0.9976 - val_loss: 0.6831 - val_acc: 0.8984\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90391\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90391\n",
      "Epoch 5/5\n",
      "50750/50750 [==============================] - 28s 548us/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.7823 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90391\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1990d65a58>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN1D_PC_CNN1D_T.h5', \n",
    "                                    save_weights_only=True, monitor='val_acc', \n",
    "                                    verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN1D_PC_CNN1D_T.h5', \n",
    "                                   save_weights_only=False, monitor='val_acc', \n",
    "                                   verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "model.fit([train_title_data,train_content_data], y_train, \n",
    "          validation_data=([val_title_data,val_content_data], y_val),\n",
    "          shuffle=True, epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN1D(Pretrain) content+title kmaxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import InputSpec, Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension).\n",
    "    TensorFlow backend.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], (input_shape[2] * self.k))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 1])\n",
    "\n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(shifted_input, k=self.k, sorted=True, name=None)[0]\n",
    "\n",
    "        # return flattened output\n",
    "        return Flatten()(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 246, 300)     25657200    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "content (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 246, 300)     0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1000, 300)    196700400   content[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 244, 250)     225250      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 998, 250)     225250      embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling_6 (KMaxPooling)   (None, 750)          0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling_7 (KMaxPooling)   (None, 750)          0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 300)          225300      k_max_pooling_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 300)          225300      k_max_pooling_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 600)          0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 14)           8414        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 223,267,114\n",
      "Trainable params: 26,566,714\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, GlobalMaxPooling1D, concatenate\n",
    "\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "dropout_t = Dropout(0.2)(embedded_sent_t)\n",
    "conv1d_t = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(dropout_t)\n",
    "flatten_t = KMaxPooling(3)(conv1d_t)\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(flatten_t)\n",
    "\n",
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH, ), dtype='int32', name='content')\n",
    "embedded_sent_c = Embedding(len(word_content_index) + 1, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix], input_length=MAX_CONTENT_LENGTH,\n",
    "                           trainable=False)(content_inputs)\n",
    "conv1d_c = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(embedded_sent_c)\n",
    "flatten_c =KMaxPooling(3)(conv1d_c)\n",
    "encode_content = Dense(EMBEDDING_DIM, activation='relu')(flatten_c)\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/5\n",
      "50750/50750 [==============================] - 69s 1ms/step - loss: 0.5195 - acc: 0.8405 - val_loss: 0.2750 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91757, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.KCNN1D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91757, saving model to /home/jovyan/jt071-group23/jt071073/model/KCNN1D_PC_KCNN1D_T.h5\n",
      "Epoch 2/5\n",
      "50750/50750 [==============================] - 66s 1ms/step - loss: 0.2087 - acc: 0.9361 - val_loss: 0.2840 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91757\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91757\n",
      "Epoch 3/5\n",
      "50750/50750 [==============================] - 66s 1ms/step - loss: 0.1325 - acc: 0.9589 - val_loss: 0.2755 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91757 to 0.91858, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.KCNN1D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91757 to 0.91858, saving model to /home/jovyan/jt071-group23/jt071073/model/KCNN1D_PC_KCNN1D_T.h5\n",
      "Epoch 4/5\n",
      "50750/50750 [==============================] - 66s 1ms/step - loss: 0.0732 - acc: 0.9760 - val_loss: 0.3070 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91858 to 0.91964, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.KCNN1D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91858 to 0.91964, saving model to /home/jovyan/jt071-group23/jt071073/model/KCNN1D_PC_KCNN1D_T.h5\n",
      "Epoch 5/5\n",
      "50750/50750 [==============================] - 67s 1ms/step - loss: 0.0394 - acc: 0.9878 - val_loss: 0.3905 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91964\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c9d9f9668>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.KCNN1D_PC_KCNN1D_T.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/KCNN1D_PC_KCNN1D_T.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "model.fit([train_title_data,train_content_data], y_train, \n",
    "          validation_data=([val_title_data,val_content_data], y_val),\n",
    "          shuffle=True, epochs=5, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN2D content + CNN1D title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, concatenate\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(len(word_content_index)+1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_CONTENT_LENGTH,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    196700400   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 246, 300)     25657200    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1000, 300, 1) 0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 246, 300)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 998, 1, 512)  461312      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 997, 1, 512)  614912      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 996, 1, 512)  768512      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 244, 250)     225250      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 81, 250)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 1, 512)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 20250)        0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1536)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 300)          6075300     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          461100      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 600)          0           dense_2[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 14)           8414        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 230,972,400\n",
      "Trainable params: 230,972,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(content_inputs)\n",
    "reshape = Reshape((MAX_CONTENT_LENGTH, EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten_c = Flatten()(concatenated_tensor)\n",
    "encode_content = Dense(EMBEDDING_DIM, activation='relu')(flatten_c)\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "dropout_t = Dropout(0.2)(embedded_sent_t)\n",
    "conv1d_t = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(dropout_t)\n",
    "flatten_t = Flatten()(MaxPooling1D(3)(conv1d_t))\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(flatten_t)\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 196700400 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/10\n",
      "50750/50750 [==============================] - 265s 5ms/step - loss: 1.1503 - acc: 0.6864 - val_loss: 0.5744 - val_acc: 0.8276\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82764, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C_CNN1D_T.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82764, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C_CNN1D_T.h5\n",
      "Epoch 2/10\n",
      "50750/50750 [==============================] - 254s 5ms/step - loss: 0.4091 - acc: 0.8783 - val_loss: 0.3875 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.82764 to 0.88194, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C_CNN1D_T.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.82764 to 0.88194, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C_CNN1D_T.h5\n",
      "Epoch 3/10\n",
      "50750/50750 [==============================] - 253s 5ms/step - loss: 0.2464 - acc: 0.9263 - val_loss: 0.3395 - val_acc: 0.8923\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88194 to 0.89228, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C_CNN1D_T.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88194 to 0.89228, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C_CNN1D_T.h5\n",
      "Epoch 4/10\n",
      "50750/50750 [==============================] - 254s 5ms/step - loss: 0.1485 - acc: 0.9589 - val_loss: 0.3054 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89228 to 0.90621, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C_CNN1D_T.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89228 to 0.90621, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_C_CNN1D_T.h5\n",
      "Epoch 5/10\n",
      "50750/50750 [==============================] - 253s 5ms/step - loss: 0.0837 - acc: 0.9813 - val_loss: 0.3024 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90621\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90621\n",
      "Epoch 6/10\n",
      "50750/50750 [==============================] - 255s 5ms/step - loss: 0.0449 - acc: 0.9923 - val_loss: 0.3148 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90621\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90621\n",
      "Epoch 7/10\n",
      "50750/50750 [==============================] - 255s 5ms/step - loss: 0.0235 - acc: 0.9973 - val_loss: 0.3286 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90621\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90621\n",
      "Epoch 8/10\n",
      "50750/50750 [==============================] - 255s 5ms/step - loss: 0.0130 - acc: 0.9991 - val_loss: 0.3376 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90621\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90621\n",
      "Epoch 9/10\n",
      "50750/50750 [==============================] - 255s 5ms/step - loss: 0.0087 - acc: 0.9993 - val_loss: 0.3551 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90621\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90621\n",
      "Epoch 10/10\n",
      "50750/50750 [==============================] - 255s 5ms/step - loss: 0.0061 - acc: 0.9994 - val_loss: 0.3730 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90621\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90621\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f77ce8b70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_C_CNN1D_T.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN2D_C_CNN1D_T.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "model.fit([train_title_data,train_content_data], y_train, \n",
    "          validation_data=([val_title_data,val_content_data], y_val),\n",
    "          shuffle=True, epochs=10, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN2D content(Pretrain)+ CNN1D title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, concatenate\n",
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(len(word_content_index)+1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_CONTENT_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1000, 300)    196700400   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 246, 300)     25657200    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1000, 300, 1) 0           embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 246, 300)     0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 998, 1, 512)  461312      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 997, 1, 512)  614912      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 996, 1, 512)  768512      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 244, 250)     225250      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 81, 250)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3, 1, 512)    0           max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 20250)        0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1536)         0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 300)          6075300     flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 300)          461100      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 600)          0           dense_8[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 14)           8414        concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 230,972,400\n",
      "Trainable params: 34,272,000\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(content_inputs)\n",
    "reshape = Reshape((MAX_CONTENT_LENGTH, EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten_c = Flatten()(concatenated_tensor)\n",
    "encode_content = Dense(EMBEDDING_DIM, activation='relu')(flatten_c)\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "dropout_t = Dropout(0.2)(embedded_sent_t)\n",
    "conv1d_t = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(dropout_t)\n",
    "flatten_t = Flatten()(MaxPooling1D(3)(conv1d_t))\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(flatten_t)\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/10\n",
      "50750/50750 [==============================] - 187s 4ms/step - loss: 1.1546 - acc: 0.6878 - val_loss: 0.6207 - val_acc: 0.8058\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80580, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_CNN1D_T.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80580, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_CNN1D_T.h5\n",
      "Epoch 2/10\n",
      "50750/50750 [==============================] - 187s 4ms/step - loss: 0.4324 - acc: 0.8709 - val_loss: 0.3943 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.80580 to 0.87761, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_CNN1D_T.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.80580 to 0.87761, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_CNN1D_T.h5\n",
      "Epoch 3/10\n",
      "50750/50750 [==============================] - 187s 4ms/step - loss: 0.2707 - acc: 0.9184 - val_loss: 0.3558 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87761 to 0.88736, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_CNN1D_T.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87761 to 0.88736, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_CNN1D_T.h5\n",
      "Epoch 4/10\n",
      "50750/50750 [==============================] - 187s 4ms/step - loss: 0.1764 - acc: 0.9487 - val_loss: 0.3172 - val_acc: 0.9023\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.88736 to 0.90235, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_CNN1D_T.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.88736 to 0.90235, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_CNN1D_T.h5\n",
      "Epoch 5/10\n",
      "50750/50750 [==============================] - 187s 4ms/step - loss: 0.1059 - acc: 0.9734 - val_loss: 0.3283 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90235\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90235\n",
      "Epoch 6/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.0602 - acc: 0.9873 - val_loss: 0.3355 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90235\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90235\n",
      "Epoch 7/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.0328 - acc: 0.9948 - val_loss: 0.3544 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90235\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90235\n",
      "Epoch 8/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.0193 - acc: 0.9979 - val_loss: 0.3715 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90235\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90235\n",
      "Epoch 9/10\n",
      "50750/50750 [==============================] - 188s 4ms/step - loss: 0.0122 - acc: 0.9987 - val_loss: 0.3949 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90235\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90235\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ed41719e8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_CNN1D_T.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_CNN1D_T.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "model.fit([train_title_data,train_content_data], y_train, \n",
    "          validation_data=([val_title_data,val_content_data], y_val),\n",
    "          shuffle=True, epochs=10, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN2D content(Pretrain)+ CNN1D title(KMaxPooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import InputSpec, Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension).\n",
    "    TensorFlow backend.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], (input_shape[2] * self.k))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 1])\n",
    "\n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(shifted_input, k=self.k, sorted=True, name=None)[0]\n",
    "\n",
    "        # return flattened output\n",
    "        return Flatten()(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1000, 300)    196700400   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1000, 300, 1) 0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 246, 300)     25657200    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 998, 1, 512)  461312      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 997, 1, 512)  614912      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 996, 1, 512)  768512      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 246, 300)     0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 244, 250)     225250      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 1, 512)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling_8 (KMaxPooling)   (None, 750)          0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 1536)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 300)          225300      k_max_pooling_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 300)          461100      flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 600)          0           dense_11[0][0]                   \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 14)           8414        concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 225,122,400\n",
      "Trainable params: 28,422,000\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(content_inputs)\n",
    "reshape = Reshape((MAX_CONTENT_LENGTH, EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten_c = Flatten()(concatenated_tensor)\n",
    "encode_content = Dense(EMBEDDING_DIM, activation='relu')(flatten_c)\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "\n",
    "dropout_t = Dropout(0.2)(embedded_sent_t)\n",
    "conv1d_t = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(dropout_t)\n",
    "flatten_t = KMaxPooling(3)(conv1d_t)\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(flatten_t)\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/10\n",
      "50750/50750 [==============================] - 192s 4ms/step - loss: 1.2196 - acc: 0.6769 - val_loss: 0.5730 - val_acc: 0.8241\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82405, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82405, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 2/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.4276 - acc: 0.8706 - val_loss: 0.3656 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.82405 to 0.88543, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.82405 to 0.88543, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 3/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.2667 - acc: 0.9200 - val_loss: 0.3266 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88543 to 0.89490, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88543 to 0.89490, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 4/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.1771 - acc: 0.9481 - val_loss: 0.2796 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89490 to 0.91113, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89490 to 0.91113, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 5/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.1086 - acc: 0.9710 - val_loss: 0.2862 - val_acc: 0.9115\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91113 to 0.91150, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91113 to 0.91150, saving model to /home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 6/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.0609 - acc: 0.9868 - val_loss: 0.2973 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91150\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91150\n",
      "Epoch 7/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.0339 - acc: 0.9941 - val_loss: 0.3211 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91150\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91150\n",
      "Epoch 8/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.0188 - acc: 0.9978 - val_loss: 0.3317 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91150\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91150\n",
      "Epoch 9/10\n",
      "50750/50750 [==============================] - 189s 4ms/step - loss: 0.0116 - acc: 0.9986 - val_loss: 0.3561 - val_acc: 0.9054\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91150\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91150\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c0c177e10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.CNN2D_PC_KCNN1D_T.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/CNN2D_PC_KCNN1D_T.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "model.fit([train_title_data,train_content_data], y_train, \n",
    "          validation_data=([val_title_data,val_content_data], y_val),\n",
    "          shuffle=True, epochs=10, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN2D content(KMaxPooling Pretrain)+ CNN1D title(KMaxPooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import InputSpec, Layer\n",
    "import tensorflow as tf\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension).\n",
    "    TensorFlow backend.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], (input_shape[2] * self.k))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 1])\n",
    "\n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(shifted_input, k=self.k, sorted=True, name=None)[0]\n",
    "\n",
    "        # return flattened output\n",
    "        return Flatten()(top_k)\n",
    "\n",
    "class KMaxPooling2D(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension).\n",
    "    TensorFlow backend.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.k, input_shape[2], input_shape[3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "\n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(shifted_input, k=self.k, sorted=True, name=None)[0]\n",
    "        # return flattened output\n",
    "        return tf.transpose(top_k, [0, 3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    196690800   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1000, 300, 1) 0           embedding_1[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 246, 300)     25616700    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 998, 1, 256)  230656      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 997, 1, 256)  307456      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 996, 1, 256)  384256      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 246, 300)     0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling2d_7 (KMaxPooling2 (None, 3, 1, 256)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling2d_8 (KMaxPooling2 (None, 3, 1, 256)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling2d_9 (KMaxPooling2 (None, 3, 1, 256)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 244, 250)     225250      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 9, 1, 256)    0           k_max_pooling2d_7[0][0]          \n",
      "                                                                 k_max_pooling2d_8[0][0]          \n",
      "                                                                 k_max_pooling2d_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling_3 (KMaxPooling)   (None, 750)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2304)         0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 300)          225300      k_max_pooling_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 300)          691500      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 600)          0           dense_8[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 14)           8414        concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 224,380,332\n",
      "Trainable params: 27,689,532\n",
      "Non-trainable params: 196,690,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_sizes = [3,4,5]\n",
    "num_filters = 256\n",
    "drop = 0.5\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(content_inputs)\n",
    "reshape = Reshape((MAX_CONTENT_LENGTH, EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = KMaxPooling2D(3)(conv_0)\n",
    "maxpool_1 = KMaxPooling2D(3)(conv_1)\n",
    "maxpool_2 = KMaxPooling2D(3)(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten_c = Flatten()(concatenated_tensor)\n",
    "encode_content = Dense(EMBEDDING_DIM, activation='relu')(flatten_c)\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "dropout_t = Dropout(0.2)(embedded_sent_t)\n",
    "conv1d_t = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(dropout_t)\n",
    "flatten_t = KMaxPooling(3)(conv1d_t)\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(flatten_t)\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55299 samples, validate on 9759 samples\n",
      "Epoch 1/10\n",
      "55299/55299 [==============================] - 143s 3ms/step - loss: 1.1753 - acc: 0.6801 - val_loss: 0.5351 - val_acc: 0.8326\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83256, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.KCNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.83256, saving model to /home/jovyan/jt071-group23/jt071073/model/KCNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 2/10\n",
      "55299/55299 [==============================] - 140s 3ms/step - loss: 0.4042 - acc: 0.8769 - val_loss: 0.3876 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83256 to 0.87868, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.KCNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.83256 to 0.87868, saving model to /home/jovyan/jt071-group23/jt071073/model/KCNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 3/10\n",
      "55299/55299 [==============================] - 140s 3ms/step - loss: 0.2686 - acc: 0.9185 - val_loss: 0.3212 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87868 to 0.89968, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.KCNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87868 to 0.89968, saving model to /home/jovyan/jt071-group23/jt071073/model/KCNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 4/10\n",
      "55299/55299 [==============================] - 141s 3ms/step - loss: 0.1856 - acc: 0.9439 - val_loss: 0.3003 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89968 to 0.90849, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.KCNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89968 to 0.90849, saving model to /home/jovyan/jt071-group23/jt071073/model/KCNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 5/10\n",
      "55299/55299 [==============================] - 140s 3ms/step - loss: 0.1216 - acc: 0.9649 - val_loss: 0.2827 - val_acc: 0.9139\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90849 to 0.91393, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.KCNN2D_PC_KCNN1D_T.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90849 to 0.91393, saving model to /home/jovyan/jt071-group23/jt071073/model/KCNN2D_PC_KCNN1D_T.h5\n",
      "Epoch 6/10\n",
      "55299/55299 [==============================] - 140s 3ms/step - loss: 0.0743 - acc: 0.9808 - val_loss: 0.2992 - val_acc: 0.9134\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91393\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91393\n",
      "Epoch 7/10\n",
      "55299/55299 [==============================] - 142s 3ms/step - loss: 0.0441 - acc: 0.9899 - val_loss: 0.3273 - val_acc: 0.9083\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91393\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91393\n",
      "Epoch 8/10\n",
      "55299/55299 [==============================] - 142s 3ms/step - loss: 0.0259 - acc: 0.9946 - val_loss: 0.3575 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91393\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91393\n",
      "Epoch 9/10\n",
      "55299/55299 [==============================] - 143s 3ms/step - loss: 0.0161 - acc: 0.9974 - val_loss: 0.3707 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91393\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91393\n",
      "Epoch 10/10\n",
      "55299/55299 [==============================] - 142s 3ms/step - loss: 0.0108 - acc: 0.9985 - val_loss: 0.3911 - val_acc: 0.9035\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91393\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.91393\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb881d17f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.KCNN2D_PC_KCNN1D_T.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/KCNN2D_PC_KCNN1D_T.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "model.fit([train_title_data,train_content_data], y_train, \n",
    "          validation_data=([val_title_data,val_content_data], y_val),\n",
    "          shuffle=True, epochs=10, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 246, 300)     25407900    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    195022200   input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 246, 300)     0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1000, 300, 1) 0           embedding_1[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 246, 300)     90300       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 245, 300)     180300      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 244, 300)     270300      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 243, 300)     360300      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 998, 1, 512)  461312      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 997, 1, 512)  614912      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 996, 1, 512)  768512      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling_3 (KMaxPooling)   (None, 900)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling_4 (KMaxPooling)   (None, 900)          0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling_5 (KMaxPooling)   (None, 900)          0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "k_max_pooling_6 (KMaxPooling)   (None, 900)          0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 1, 1, 512)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 1, 1, 512)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 1, 1, 512)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 3600)         0           k_max_pooling_3[0][0]            \n",
      "                                                                 k_max_pooling_4[0][0]            \n",
      "                                                                 k_max_pooling_5[0][0]            \n",
      "                                                                 k_max_pooling_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3, 1, 512)    0           max_pooling2d_10[0][0]           \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 3600)         0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 1536)         0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 300)          1080300     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 300)          461100      flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 600)          0           dense_11[0][0]                   \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 14)           8414        concatenate_9[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 224,725,850\n",
      "Trainable params: 29,703,650\n",
      "Non-trainable params: 195,022,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SpatialDropout1D\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(content_inputs)\n",
    "reshape = Reshape((MAX_CONTENT_LENGTH, EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_CONTENT_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten_c = Flatten()(concatenated_tensor)\n",
    "encode_content = Dense(EMBEDDING_DIM, activation='relu')(flatten_c)\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "dropout_t = SpatialDropout1D(0.2)(embedded_sent_t)\n",
    "\n",
    "conv_0_t = Conv1D(300, 1, kernel_initializer=\"normal\", padding=\"valid\", activation=\"relu\")(dropout_t)\n",
    "conv_1_t = Conv1D(300, 2, kernel_initializer=\"normal\", padding=\"valid\", activation=\"relu\")(dropout_t)\n",
    "conv_2_t = Conv1D(300, 3, kernel_initializer=\"normal\", padding=\"valid\", activation=\"relu\")(dropout_t)\n",
    "conv_3_t = Conv1D(300, 4, kernel_initializer=\"normal\", padding=\"valid\", activation=\"relu\")(dropout_t)\n",
    "\n",
    "maxpool_0_t = KMaxPooling(k=3)(conv_0_t)\n",
    "maxpool_1_t = KMaxPooling(k=3)(conv_1_t)\n",
    "maxpool_2_t = KMaxPooling(k=3)(conv_2_t)\n",
    "maxpool_3_t = KMaxPooling(k=3)(conv_3_t)\n",
    "\n",
    "concatenated_tensor_t = Concatenate(axis=1)([maxpool_0_t, maxpool_1_t, maxpool_2_t, maxpool_3_t])\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(Dropout(0.6)(concatenated_tensor_t))\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49700 samples, validate on 21300 samples\n",
      "Epoch 1/10\n",
      "49700/49700 [==============================] - 223s 4ms/step - loss: 1.2802 - acc: 0.6628 - val_loss: 0.6146 - val_acc: 0.8139\n",
      "Epoch 2/10\n",
      "49700/49700 [==============================] - 221s 4ms/step - loss: 0.4609 - acc: 0.8663 - val_loss: 0.3754 - val_acc: 0.8859\n",
      "Epoch 3/10\n",
      "49700/49700 [==============================] - 221s 4ms/step - loss: 0.2922 - acc: 0.9143 - val_loss: 0.3020 - val_acc: 0.9045\n",
      "Epoch 4/10\n",
      "49700/49700 [==============================] - 220s 4ms/step - loss: 0.2054 - acc: 0.9411 - val_loss: 0.2754 - val_acc: 0.9123\n",
      "Epoch 5/10\n",
      "49700/49700 [==============================] - 220s 4ms/step - loss: 0.1383 - acc: 0.9622 - val_loss: 0.2641 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "49700/49700 [==============================] - 220s 4ms/step - loss: 0.0888 - acc: 0.9775 - val_loss: 0.2648 - val_acc: 0.9174\n",
      "Epoch 7/10\n",
      "49700/49700 [==============================] - 220s 4ms/step - loss: 0.0525 - acc: 0.9889 - val_loss: 0.2745 - val_acc: 0.9177\n",
      "Epoch 8/10\n",
      "49700/49700 [==============================] - 220s 4ms/step - loss: 0.0309 - acc: 0.9948 - val_loss: 0.2875 - val_acc: 0.9154\n",
      "Epoch 9/10\n",
      "49700/49700 [==============================] - 220s 4ms/step - loss: 0.0185 - acc: 0.9977 - val_loss: 0.3018 - val_acc: 0.9141\n",
      "Epoch 10/10\n",
      "49700/49700 [==============================] - 220s 4ms/step - loss: 0.0121 - acc: 0.9987 - val_loss: 0.3147 - val_acc: 0.9146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4aee72e4a8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_title_data,train_content_data], y_train, validation_data=([val_title_data,val_content_data], y_val), epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttentionGRU content(Pretrain)+CNN1D title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input, Embedding, Lambda, Dropout, Activation, SpatialDropout1D, Reshape, GlobalAveragePooling1D, merge, Flatten, Bidirectional, CuDNNGRU, add, Conv1D, GlobalMaxPooling1D, Concatenate\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension).\n",
    "    TensorFlow backend.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], (input_shape[2] * self.k))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        shifted_input = tf.transpose(inputs, [0, 2, 1])\n",
    "\n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(shifted_input, k=self.k, sorted=True, name=None)[0]\n",
    "\n",
    "        # return flattened output\n",
    "        return Flatten()(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "content (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1000, 300)    196700400   content[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1000, 300)    0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 1000, 120)    130320      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 246, 300)     25657200    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 1000, 120)    65520       bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 246, 300)     0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1000, 240)    0           bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 244, 250)     225250      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "last (Lambda)                   (None, 240)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 240)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 240)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_3 (A (None, 240)          240         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 81, 250)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 960)          0           last[0][0]                       \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "                                                                 attention_weighted_average_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 20250)        0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 960)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 300)          6075300     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 300)          288300      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 600)          0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 14)           8414        concatenate_9[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 229,150,944\n",
      "Trainable params: 32,450,544\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, GlobalMaxPooling1D, concatenate\n",
    "\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "dropout_t = Dropout(0.2)(embedded_sent_t)\n",
    "conv1d_t = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(dropout_t)\n",
    "flatten_t = Flatten()(MaxPooling1D(3)(conv1d_t))\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(flatten_t)\n",
    "\n",
    "\n",
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH, ), dtype='int32', name='content')\n",
    "embedded_sent_c = Embedding(len(word_content_index) + 1, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix], input_length=MAX_CONTENT_LENGTH,\n",
    "                           trainable=False)(content_inputs)\n",
    "embedded_sent_c = SpatialDropout1D(0.25)(embedded_sent_c)\n",
    "rnn_1 = Bidirectional(CuDNNGRU(60, return_sequences=True))(embedded_sent_c)\n",
    "rnn_2 = Bidirectional(CuDNNGRU(60, return_sequences=True))(rnn_1)\n",
    "concat_rnn = concatenate([rnn_1, rnn_2], axis=2)\n",
    "last = Lambda(lambda t: t[:, -1], name='last')(concat_rnn)\n",
    "maxpool = GlobalMaxPooling1D()(concat_rnn)\n",
    "attn = AttentionWeightedAverage()(concat_rnn)\n",
    "average = GlobalAveragePooling1D()(concat_rnn)\n",
    "all_views = Concatenate(axis=1)([last, maxpool, average, attn])\n",
    "drop_c = Dropout(0.5)(all_views)\n",
    "encode_content = Dense(EMBEDDING_DIM, activation=\"relu\")(drop_c)\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/10\n",
      "50750/50750 [==============================] - 117s 2ms/step - loss: 0.6748 - acc: 0.7977 - val_loss: 0.4331 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86447, saving model to /home/jovyan/jt071-group23/jt071073/model/weights.AVRNN_CP_CNN1D_T.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86447, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_CP_CNN1D_T.h5\n",
      "Epoch 2/10\n",
      "50750/50750 [==============================] - 115s 2ms/step - loss: 0.2680 - acc: 0.9189 - val_loss: 0.3590 - val_acc: 0.8944\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86447 to 0.89440, saving model to /home/jovyan/jt071-group23/jt071073/model/weights.AVRNN_CP_CNN1D_T.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.86447 to 0.89440, saving model to /home/jovyan/jt071-group23/jt071073/model/AVRNN_CP_CNN1D_T.h5\n",
      "Epoch 3/10\n",
      "50750/50750 [==============================] - 115s 2ms/step - loss: 0.1685 - acc: 0.9496 - val_loss: 0.3893 - val_acc: 0.8904\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89440\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89440\n",
      "Epoch 4/10\n",
      "50750/50750 [==============================] - 115s 2ms/step - loss: 0.0915 - acc: 0.9735 - val_loss: 0.4571 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89440\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89440\n",
      "Epoch 5/10\n",
      "50750/50750 [==============================] - 115s 2ms/step - loss: 0.0446 - acc: 0.9885 - val_loss: 0.5837 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89440\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89440\n",
      "Epoch 6/10\n",
      "50750/50750 [==============================] - 116s 2ms/step - loss: 0.0236 - acc: 0.9946 - val_loss: 0.6868 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89440\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89440\n",
      "Epoch 7/10\n",
      "50750/50750 [==============================] - 116s 2ms/step - loss: 0.0195 - acc: 0.9963 - val_loss: 0.8729 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89440\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89440\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78e71948d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weights.AVRNN_CP_CNN1D_T.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/AVRNN_CP_CNN1D_T.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "model.fit([train_title_data,train_content_data], y_train, \n",
    "          validation_data=([val_title_data,val_content_data], y_val),\n",
    "          shuffle=True, epochs=10, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiGru content(Pretrain) + CNN1D title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "content (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1000, 300)    196700400   content[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1000, 300)    0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "title (InputLayer)              (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 1000, 128)    140544      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 246, 300)     25657200    title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1000, 128)    0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 246, 300)     0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 1000, 128)    74496       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 244, 250)     225250      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 128)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 81, 250)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 384)          0           lambda_1[0][0]                   \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 20250)        0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 384)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 300)          6075300     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 300)          115500      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 600)          0           dense_11[0][0]                   \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 14)           8414        concatenate_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 228,997,104\n",
      "Trainable params: 32,296,704\n",
      "Non-trainable params: 196,700,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "content_inputs = Input(shape=(MAX_CONTENT_LENGTH, ), dtype='int32', name='content')\n",
    "embedded_sent_c = Embedding(len(word_content_index) + 1, EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix], input_length=MAX_CONTENT_LENGTH,\n",
    "                           trainable=False)(content_inputs)\n",
    "embedded_sent_c = SpatialDropout1D(0.25)(embedded_sent_c)\n",
    "embedded_sent_c = Bidirectional(CuDNNGRU(64, return_sequences=True))(embedded_sent_c)\n",
    "embedded_sent_c = Dropout(0.35)(embedded_sent_c)\n",
    "embedded_sent_c = Bidirectional(CuDNNGRU(64, return_sequences=True))(embedded_sent_c)\n",
    "\n",
    "last = Lambda(lambda t: t[:, -1])(embedded_sent_c)\n",
    "maxpool = GlobalMaxPooling1D()(embedded_sent_c)\n",
    "average = GlobalAveragePooling1D()(embedded_sent_c)\n",
    "concatenated = Concatenate(axis=1)([last, maxpool, average])\n",
    "drop_c = Dropout(0.5)(concatenated)\n",
    "encode_content = Dense(EMBEDDING_DIM, activation=\"relu\")(drop_c)\n",
    "\n",
    "title_inputs = Input(shape=(MAX_TITLE_LENGTH, ), dtype='int32', name='title')\n",
    "embedded_sent_t = Embedding(len(word_title_index) + 1, EMBEDDING_DIM, \n",
    "                            input_length=MAX_TITLE_LENGTH)(title_inputs)\n",
    "dropout_t = Dropout(0.2)(embedded_sent_t)\n",
    "conv1d_t = Conv1D(250, 3, padding='valid', activation='relu', strides=1)(dropout_t)\n",
    "flatten_t = Flatten()(MaxPooling1D(3)(conv1d_t))\n",
    "encode_title = Dense(EMBEDDING_DIM, activation='elu')(flatten_t)\n",
    "\n",
    "concatenated = concatenate([encode_title,encode_content], axis=-1)\n",
    "outputs = Dense(labels.shape[1], activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(inputs=[title_inputs,content_inputs], outputs=outputs)\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50750 samples, validate on 21751 samples\n",
      "Epoch 1/10\n",
      "50750/50750 [==============================] - 115s 2ms/step - loss: 1.7370 - acc: 0.4673 - val_loss: 0.8579 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74489, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGru_CP_CNN1D_T.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74489, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGru_CP_CNN1D_T.h5\n",
      "Epoch 2/10\n",
      "50750/50750 [==============================] - 112s 2ms/step - loss: 0.6423 - acc: 0.8017 - val_loss: 0.5069 - val_acc: 0.8461\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74489 to 0.84608, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGru_CP_CNN1D_T.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74489 to 0.84608, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGru_CP_CNN1D_T.h5\n",
      "Epoch 3/10\n",
      "50750/50750 [==============================] - 112s 2ms/step - loss: 0.3890 - acc: 0.8840 - val_loss: 0.4223 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84608 to 0.87527, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGru_CP_CNN1D_T.h5\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.84608 to 0.87527, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGru_CP_CNN1D_T.h5\n",
      "Epoch 4/10\n",
      "50750/50750 [==============================] - 112s 2ms/step - loss: 0.2581 - acc: 0.9265 - val_loss: 0.4085 - val_acc: 0.8794\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87527 to 0.87936, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGru_CP_CNN1D_T.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87527 to 0.87936, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGru_CP_CNN1D_T.h5\n",
      "Epoch 5/10\n",
      "50750/50750 [==============================] - 112s 2ms/step - loss: 0.1728 - acc: 0.9530 - val_loss: 0.4244 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87936 to 0.87973, saving model to /home/jovyan/jt071-group23/jt071073/model/weight.BiGru_CP_CNN1D_T.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.87936 to 0.87973, saving model to /home/jovyan/jt071-group23/jt071073/model/BiGru_CP_CNN1D_T.h5\n",
      "Epoch 6/10\n",
      "50750/50750 [==============================] - 112s 2ms/step - loss: 0.1148 - acc: 0.9693 - val_loss: 0.4485 - val_acc: 0.8772\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87973\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87973\n",
      "Epoch 7/10\n",
      "50750/50750 [==============================] - 113s 2ms/step - loss: 0.0767 - acc: 0.9815 - val_loss: 0.4861 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87973\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.87973\n",
      "Epoch 8/10\n",
      "50750/50750 [==============================] - 112s 2ms/step - loss: 0.0526 - acc: 0.9877 - val_loss: 0.5265 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87973\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.87973\n",
      "Epoch 9/10\n",
      "50750/50750 [==============================] - 113s 2ms/step - loss: 0.0377 - acc: 0.9915 - val_loss: 0.5671 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.87973\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.87973\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78e71a96d8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_weight = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/weight.BiGru_CP_CNN1D_T.h5', save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "checkpoint_model = ModelCheckpoint('/home/jovyan/jt071-group23/jt071073/model/BiGru_CP_CNN1D_T.h5', save_weights_only=False, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "model.fit([train_title_data,train_content_data], y_train, \n",
    "          validation_data=([val_title_data,val_content_data], y_val),\n",
    "          shuffle=True, epochs=10, batch_size=128,\n",
    "          callbacks=[earlystop, checkpoint_weight, checkpoint_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
