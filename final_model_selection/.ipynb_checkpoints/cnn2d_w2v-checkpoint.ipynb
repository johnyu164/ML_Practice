{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_uniqcontent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>eigenWords</th>\n",
       "      <th>topKeyWords</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>class_no</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sentences_1000</th>\n",
       "      <th>sentences_1000_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.topgeartw.com/?p=8456</td>\n",
       "      <td>['content', '豪哥', 'com', 'jpg', 'uploads', 'ww...</td>\n",
       "      <td>['chao', 'com', 'content', 'image', 'info', 'i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>豪哥發威 便知有沒有 – TopGear</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.blocktempo.com/cryptoexchange-max-...</td>\n",
       "      <td>['交易', '基於', '交易所', '宣布', '以太', '貨幣', 'usdt', ...</td>\n",
       "      <td>['asset', 'asset exchange', 'coin', 'doubt', '...</td>\n",
       "      <td>\b4月23日晚間，7點46分，Maicoin旗下的虛擬貨幣交易所MaicoinAssetEx...</td>\n",
       "      <td>【MAX交易所宣布支援USDT】基於以太坊 ERC-20 的 USDT 跟原本的USDT差在...</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\x08', '月', '日', '晚間', '點', '分', 'Maicoin', ...</td>\n",
       "      <td>['\\x08', '月', '日', '晚間', '點', '分', 'Maicoin', ...</td>\n",
       "      <td>\b 月 日 晚間 點 分 Maicoin 旗下 虛擬 貨幣 交易所 MaicoinAsset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://womany.net/read/article/15331?ref=rss&amp;u...</td>\n",
       "      <td>['工作', '轉職', '什麼', '自己', '公司', '辭職', '這份', '滿意...</td>\n",
       "      <td>['一下', '一個', '一定', '一年', '一樣', '一直', '下一', '不一...</td>\n",
       "      <td>\b你有轉職的考量嗎？你現今的工作可以符合你對未來人生的規劃嗎？透過五個轉職思考向度，檢視自己...</td>\n",
       "      <td>年前轉職：什麼情況下，你該毫不猶豫的換工作？｜女人迷 Womany</td>\n",
       "      <td>10</td>\n",
       "      <td>['\\x08', '轉職', '考量', '現今', '工作', '符合', '未來', '...</td>\n",
       "      <td>['\\x08', '轉職', '考量', '現今', '工作', '符合', '未來', '...</td>\n",
       "      <td>\b 轉職 考量 現今 工作 符合 未來 人生 規劃 透過 五個 轉職 思考 向度 檢視 是否...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.blocktempo.com/facebook-we-cant-co...</td>\n",
       "      <td>['數據', '區塊', '所有', '資料', '透過', '中心化', '市場', '用...</td>\n",
       "      <td>['analytica', 'cambridge', 'cambridge analytic...</td>\n",
       "      <td>\b在網路時代，金錢可能不再是最吸引人事物，有一群人正覬覦著你的資料。透過數據收買你的心早在2...</td>\n",
       "      <td>【獨立觀點】當臉書用戶個資遭濫用，區塊鏈卻試圖幫你拿回「數據所有權」 – BlockTemp...</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...</td>\n",
       "      <td>['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...</td>\n",
       "      <td>\b 網路 時代 金錢 最 吸引 人 事物 一群 人正 覬覦 資料 透過 數據 收買 心早 美...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.blocktempo.com/facebook-we-cant-co...</td>\n",
       "      <td>['數據', '區塊', '所有', '資料', '臉書', '透過', '用戶', '中心...</td>\n",
       "      <td>['cambrigde', 'cambrigde analytica', 'datummar...</td>\n",
       "      <td>\b在網路時代，金錢可能不再是最吸引人事物，有一群人正覬覦著你的資料。透過數據收買你的心早在2...</td>\n",
       "      <td>【獨立觀點】當臉書用戶個資造濫用，區塊鏈卻試圖幫你拿回「數據所有權」 – BlockTemp...</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...</td>\n",
       "      <td>['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...</td>\n",
       "      <td>\b 網路 時代 金錢 最 吸引 人 事物 一群 人正 覬覦 資料 透過 數據 收買 心早 美...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0                   http://www.topgeartw.com/?p=8456   \n",
       "1  https://www.blocktempo.com/cryptoexchange-max-...   \n",
       "2  http://womany.net/read/article/15331?ref=rss&u...   \n",
       "3  https://www.blocktempo.com/facebook-we-cant-co...   \n",
       "4  https://www.blocktempo.com/facebook-we-cant-co...   \n",
       "\n",
       "                                          eigenWords  \\\n",
       "0  ['content', '豪哥', 'com', 'jpg', 'uploads', 'ww...   \n",
       "1  ['交易', '基於', '交易所', '宣布', '以太', '貨幣', 'usdt', ...   \n",
       "2  ['工作', '轉職', '什麼', '自己', '公司', '辭職', '這份', '滿意...   \n",
       "3  ['數據', '區塊', '所有', '資料', '透過', '中心化', '市場', '用...   \n",
       "4  ['數據', '區塊', '所有', '資料', '臉書', '透過', '用戶', '中心...   \n",
       "\n",
       "                                         topKeyWords  \\\n",
       "0  ['chao', 'com', 'content', 'image', 'info', 'i...   \n",
       "1  ['asset', 'asset exchange', 'coin', 'doubt', '...   \n",
       "2  ['一下', '一個', '一定', '一年', '一樣', '一直', '下一', '不一...   \n",
       "3  ['analytica', 'cambridge', 'cambridge analytic...   \n",
       "4  ['cambrigde', 'cambrigde analytica', 'datummar...   \n",
       "\n",
       "                                             content  \\\n",
       "0                                                NaN   \n",
       "1  \b4月23日晚間，7點46分，Maicoin旗下的虛擬貨幣交易所MaicoinAssetEx...   \n",
       "2  \b你有轉職的考量嗎？你現今的工作可以符合你對未來人生的規劃嗎？透過五個轉職思考向度，檢視自己...   \n",
       "3  \b在網路時代，金錢可能不再是最吸引人事物，有一群人正覬覦著你的資料。透過數據收買你的心早在2...   \n",
       "4  \b在網路時代，金錢可能不再是最吸引人事物，有一群人正覬覦著你的資料。透過數據收買你的心早在2...   \n",
       "\n",
       "                                               title  class_no  \\\n",
       "0                               豪哥發威 便知有沒有 – TopGear         7   \n",
       "1  【MAX交易所宣布支援USDT】基於以太坊 ERC-20 的 USDT 跟原本的USDT差在...         8   \n",
       "2                  年前轉職：什麼情況下，你該毫不猶豫的換工作？｜女人迷 Womany        10   \n",
       "3  【獨立觀點】當臉書用戶個資遭濫用，區塊鏈卻試圖幫你拿回「數據所有權」 – BlockTemp...         8   \n",
       "4  【獨立觀點】當臉書用戶個資造濫用，區塊鏈卻試圖幫你拿回「數據所有權」 – BlockTemp...         8   \n",
       "\n",
       "                                           sentences  \\\n",
       "0                                                 []   \n",
       "1  ['\\x08', '月', '日', '晚間', '點', '分', 'Maicoin', ...   \n",
       "2  ['\\x08', '轉職', '考量', '現今', '工作', '符合', '未來', '...   \n",
       "3  ['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...   \n",
       "4  ['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...   \n",
       "\n",
       "                                      sentences_1000  \\\n",
       "0                                                 []   \n",
       "1  ['\\x08', '月', '日', '晚間', '點', '分', 'Maicoin', ...   \n",
       "2  ['\\x08', '轉職', '考量', '現今', '工作', '符合', '未來', '...   \n",
       "3  ['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...   \n",
       "4  ['\\x08', '網路', '時代', '金錢', '最', '吸引', '人', '事物...   \n",
       "\n",
       "                                  sentences_1000_str  \n",
       "0                                                NaN  \n",
       "1  \b 月 日 晚間 點 分 Maicoin 旗下 虛擬 貨幣 交易所 MaicoinAsset...  \n",
       "2  \b 轉職 考量 現今 工作 符合 未來 人生 規劃 透過 五個 轉職 思考 向度 檢視 是否...  \n",
       "3  \b 網路 時代 金錢 最 吸引 人 事物 一群 人正 覬覦 資料 透過 數據 收買 心早 美...  \n",
       "4  \b 網路 時代 金錢 最 吸引 人 事物 一群 人正 覬覦 資料 透過 數據 收買 心早 美...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[pd.isnull(df['sentences_1000_str'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['content'].str.len()<30].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['sentences_1000_str'])\n",
    "sequences = tokenizer.texts_to_sequences(df['sentences_1000_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (81450, 1000)\n",
      "Shape of label tensor: (81450, 14)\n"
     ]
    }
   ],
   "source": [
    "all_data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = to_categorical(np.asarray(df['class_no']))\n",
    "print('Shape of data tensor:', all_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val = train_test_split(all_data,labels,test_size=0.3,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57015, 1000), (57015, 14))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "wv_model = word2vec.KeyedVectors.load_word2vec_format('./renmin_zh_tw.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "word_vectors = wv_model.wv\n",
    "for word, vocab_obj in wv_model.wv.vocab.items():\n",
    "    embeddings_index[word] = word_vectors[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index), EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(len(word_index),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 300)    209054400   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1000, 300, 1) 0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 998, 1, 512)  461312      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 997, 1, 512)  614912      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 996, 1, 512)  768512      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 1, 512)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1536)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1536)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 14)           21518       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 210,920,654\n",
      "Trainable params: 1,866,254\n",
      "Non-trainable params: 209,054,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "inputs = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedding = embedding_layer(inputs)\n",
    "reshape = Reshape((MAX_SEQUENCE_LENGTH,EMBEDDING_DIM,1))(embedding)\n",
    "\n",
    "conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], EMBEDDING_DIM), padding='valid', kernel_initializer='normal', activation='relu')(reshape)\n",
    "\n",
    "maxpool_0 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(conv_0)\n",
    "maxpool_1 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(MAX_SEQUENCE_LENGTH - filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')(conv_2)\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "dropout = Dropout(drop)(flatten)\n",
    "output = Dense(units=labels.shape[1], activation='softmax')(dropout)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57015 samples, validate on 24435 samples\n",
      "Epoch 1/30\n",
      "57015/57015 [==============================] - 194s 3ms/step - loss: 0.1413 - acc: 0.9632 - val_loss: 0.5421 - val_acc: 0.8220\n",
      "Epoch 2/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.1321 - acc: 0.9659 - val_loss: 0.5477 - val_acc: 0.8217\n",
      "Epoch 3/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.1266 - acc: 0.9668 - val_loss: 0.5453 - val_acc: 0.8211\n",
      "Epoch 4/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.1205 - acc: 0.9692 - val_loss: 0.5542 - val_acc: 0.8202\n",
      "Epoch 5/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.1132 - acc: 0.9720 - val_loss: 0.5527 - val_acc: 0.8208\n",
      "Epoch 6/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.1072 - acc: 0.9740 - val_loss: 0.5549 - val_acc: 0.8211\n",
      "Epoch 7/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.1011 - acc: 0.9752 - val_loss: 0.5563 - val_acc: 0.8228\n",
      "Epoch 8/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0976 - acc: 0.9765 - val_loss: 0.5648 - val_acc: 0.8211\n",
      "Epoch 9/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0916 - acc: 0.9790 - val_loss: 0.5629 - val_acc: 0.8214\n",
      "Epoch 10/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0896 - acc: 0.9784 - val_loss: 0.5698 - val_acc: 0.8219\n",
      "Epoch 11/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0855 - acc: 0.9796 - val_loss: 0.5742 - val_acc: 0.8216\n",
      "Epoch 12/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0801 - acc: 0.9811 - val_loss: 0.5787 - val_acc: 0.8212\n",
      "Epoch 13/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0752 - acc: 0.9828 - val_loss: 0.5781 - val_acc: 0.8221\n",
      "Epoch 14/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0730 - acc: 0.9835 - val_loss: 0.5888 - val_acc: 0.8196\n",
      "Epoch 15/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0701 - acc: 0.9841 - val_loss: 0.5860 - val_acc: 0.8223\n",
      "Epoch 16/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0676 - acc: 0.9848 - val_loss: 0.5917 - val_acc: 0.8222\n",
      "Epoch 17/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0650 - acc: 0.9855 - val_loss: 0.5896 - val_acc: 0.8221\n",
      "Epoch 18/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0620 - acc: 0.9860 - val_loss: 0.5914 - val_acc: 0.8214\n",
      "Epoch 19/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0596 - acc: 0.9865 - val_loss: 0.6028 - val_acc: 0.8208\n",
      "Epoch 20/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0575 - acc: 0.9870 - val_loss: 0.6045 - val_acc: 0.8212\n",
      "Epoch 21/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0559 - acc: 0.9872 - val_loss: 0.6029 - val_acc: 0.8221\n",
      "Epoch 22/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0539 - acc: 0.9881 - val_loss: 0.6151 - val_acc: 0.8208\n",
      "Epoch 23/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0509 - acc: 0.9893 - val_loss: 0.6157 - val_acc: 0.8214\n",
      "Epoch 24/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0511 - acc: 0.9888 - val_loss: 0.6176 - val_acc: 0.8225\n",
      "Epoch 25/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0487 - acc: 0.9896 - val_loss: 0.6212 - val_acc: 0.8223\n",
      "Epoch 26/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0476 - acc: 0.9895 - val_loss: 0.6212 - val_acc: 0.8221\n",
      "Epoch 27/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0438 - acc: 0.9910 - val_loss: 0.6263 - val_acc: 0.8232\n",
      "Epoch 28/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0449 - acc: 0.9902 - val_loss: 0.6357 - val_acc: 0.8225\n",
      "Epoch 29/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0424 - acc: 0.9912 - val_loss: 0.6436 - val_acc: 0.8230\n",
      "Epoch 30/30\n",
      "57015/57015 [==============================] - 196s 3ms/step - loss: 0.0411 - acc: 0.9913 - val_loss: 0.6374 - val_acc: 0.8225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6d02e0e10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=30, verbose=1, validation_data=(x_val, y_val))  # starts training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
